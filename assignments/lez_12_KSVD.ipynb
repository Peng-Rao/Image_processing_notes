{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4OrCm2aFXhE"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKVyjdHyIvBa"
   },
   "outputs": [],
   "source": [
    "rootfolder = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NB1-MvmFsot"
   },
   "source": [
    "Useful function for plot a 2D dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M, N = D.shape\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    nnn = int(np.ceil(np.sqrt(N)))\n",
    "    bound = 2\n",
    "    img = np.ones((nnn * p + bound * (nnn - 1), nnn * p + bound * (nnn - 1)))\n",
    "    for i in range(N):\n",
    "        m = np.mod(i, nnn)\n",
    "        n = int((i - m) / nnn)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m : m + p, n : n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elxPQr5jRssy"
   },
   "source": [
    "Define a function that implements the OMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEEtx02YRxui"
   },
   "outputs": [],
   "source": [
    "def OMP(s, D, L, tau):\n",
    "    _, N = D.shape\n",
    "    r = s.copy()  # initial residual\n",
    "    omega = []  # support set\n",
    "    x_OMP = np.zeros(N)  # final sparse code\n",
    "\n",
    "    while len(omega) < L and np.linalg.norm(r) > tau:\n",
    "        # SWEEP STEP: compute correlations between residual and dictionary atoms\n",
    "        e = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            e[j] = D[:, j].T @ r\n",
    "\n",
    "        # find the column index with maximum correlation\n",
    "        jStar = np.argmax(np.abs(e))\n",
    "\n",
    "        # UPDATE support set\n",
    "        if jStar not in omega:\n",
    "            omega.append(jStar)\n",
    "\n",
    "        # update coefficients using least squares\n",
    "        D_omega = D[:, omega]\n",
    "        x_omega, _, _, _ = np.linalg.lstsq(D_omega, s, rcond=None)\n",
    "\n",
    "        # update residual\n",
    "        r = s - D_omega @ x_omega\n",
    "\n",
    "    # construct full sparse vector\n",
    "    for i, idx in enumerate(omega):\n",
    "        x_OMP[idx] = x_omega[i]\n",
    "\n",
    "    return x_OMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENFQwMcaI9aR"
   },
   "source": [
    "## Dictionary Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XF0xLVZyGCBc"
   },
   "source": [
    "Load the image and rescale it in $[0,1]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZXPMFW2F-W1"
   },
   "outputs": [],
   "source": [
    "path_image = (\n",
    "    f\"{rootfolder}/data/barbara.png\"  #  barbara.png, cameraman.png, Lena512.png\n",
    ")\n",
    "\n",
    "img = imread(path_image) / 255\n",
    "\n",
    "imsz = img.shape\n",
    "\n",
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patch\n",
    "M = p**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBSmSG5GIPe"
   },
   "source": [
    "Extract a bunch of random patches from the image and build the training set $S$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1NfJRxKGKFu"
   },
   "outputs": [],
   "source": [
    "npatch = 10000\n",
    "\n",
    "S = np.zeros((M, npatch))\n",
    "# S ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1zq_JGPeL"
   },
   "source": [
    "Remove the mean from the patches (each column of $S$ must have zero-mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OtzbfA_GRIA"
   },
   "outputs": [],
   "source": [
    "# S =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6MOxJJOTuK1"
   },
   "source": [
    "Define a function that implements the KSVD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue9PsXb9Txk2"
   },
   "outputs": [],
   "source": [
    "def ksvd(S, M, N, max_iter, npatch, L, print_time=False):\n",
    "\n",
    "    # intialize the dictionary\n",
    "    # D =\n",
    "\n",
    "    # normalize each column of D (zero mean and unit norm)\n",
    "    # UPDATE D\n",
    "\n",
    "    # initialize the coefficient matrix\n",
    "    X = np.zeros((N, npatch))\n",
    "\n",
    "    # Main KSVD loop\n",
    "    for iter in range(max_iter):\n",
    "        time_start = time.time()\n",
    "\n",
    "        # Sparse coding step\n",
    "        # perform the sparse coding via OMP of all the columns of S\n",
    "        for n in range(npatch):\n",
    "            # X[:, n] =\n",
    "\n",
    "        # Dictionary update step\n",
    "        # iterate over the columns of D\n",
    "        for j in range(N):\n",
    "            # find which signals uses the j-th atom in the sparse coding\n",
    "            # omega =\n",
    "\n",
    "            if len(omega) == 0:\n",
    "                # if the atom is never used then ignore or substitute it with a random vector\n",
    "            else:\n",
    "                # compute the residual matrix E, ignoring the j-th atom\n",
    "                # E =\n",
    "\n",
    "                # restrict E to the columns indicated by omega\n",
    "                # Eomega =\n",
    "\n",
    "                # Compute the best rank-1 approximation\n",
    "                # U, Sigma, V =\n",
    "\n",
    "                # update the dictionary\n",
    "                # D\n",
    "\n",
    "                # update the coefficient matrix\n",
    "                # X\n",
    "\n",
    "        time_end = time.time()\n",
    "        if print_time:\n",
    "            print(f'Iteration {iter} runtime: {time_end-time_start}')\n",
    "\n",
    "    return D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgGdWipTTXW-"
   },
   "outputs": [],
   "source": [
    "# number of columns of the dictionary\n",
    "N = 256\n",
    "\n",
    "# number of iteration of the KSVD\n",
    "max_iter = 10\n",
    "\n",
    "# maximum number of nonzero coefficients for the sparse coding\n",
    "L = 4\n",
    "\n",
    "\n",
    "# Call the KSVD implementation\n",
    "# D ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhGFrleuTzyn"
   },
   "source": [
    "Show the learned dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZV1qd-DT5vG"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(f\"Image {path_image.split('/')[-1]}\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "img_dict = get_dictionary_img(D)\n",
    "ax[1].imshow(img_dict, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Dictionary learned from {path_image.split('/')[-1]}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i8fH4GcMPSpN"
   },
   "source": [
    "## OMP denoising with learned dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7e70IsjPc81"
   },
   "outputs": [],
   "source": [
    "img_clean = imread(f\"{rootfolder}/data/barbara.png\") / 255\n",
    "\n",
    "# Corrupte the image\n",
    "\n",
    "sigma_noise = 20 / 255\n",
    "# noisy_img ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sAFV-D1qPsyW"
   },
   "outputs": [],
   "source": [
    "# psnr_noisy ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xNB_n9joPyFE"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img_clean, cmap=\"gray\")\n",
    "ax[0].set_title(f\"Original image (barbara.png)\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Noisy image, PSNR = {psnr_noisy:.2f}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0-9ZG5o5P1Q3"
   },
   "outputs": [],
   "source": [
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patch\n",
    "M = p**2\n",
    "\n",
    "# number of columns of the dictionary\n",
    "N = 256\n",
    "\n",
    "# number of iteration of the KSVD\n",
    "max_iter = 10\n",
    "\n",
    "# maximum number of nonzero coefficients for the sparse coding\n",
    "L = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5K58xgmQCQM"
   },
   "source": [
    "Generic dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6bcyFFOTP_0n"
   },
   "outputs": [],
   "source": [
    "D_generic = loadmat(f\"{rootfolder}/data/dict_nat_img.mat\")[\"D\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmwEZ4-8QEvD"
   },
   "source": [
    "Dictionary learned from a different image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tNjWo3UrQFJq"
   },
   "outputs": [],
   "source": [
    "img = imread(f\"{rootfolder}/data/cameraman.png\") / 255\n",
    "\n",
    "# Extract random patches\n",
    "npatch = 10000\n",
    "\n",
    "S = S - np.mean(S, axis=0, keepdims=True)\n",
    "\n",
    "# S =\n",
    "\n",
    "# Learn the dictionary\n",
    "# D_diff ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-nCtt-K1QYsf"
   },
   "source": [
    "Dictionary learned from the noisy image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-4wkSoNWQY7y"
   },
   "outputs": [],
   "source": [
    "# Extract random patches\n",
    "npatch = 10000\n",
    "\n",
    "# S =\n",
    "\n",
    "\n",
    "# Learn the dictionary\n",
    "# D_noisy ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IoUlEjIiQqFq"
   },
   "source": [
    "Dictionary learned from the clean image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAALKoBGQqlF"
   },
   "outputs": [],
   "source": [
    "# Extract random patches\n",
    "npatch = 10000\n",
    "\n",
    "# S = S - np.mean(S, axis=0, keepdims=True)\n",
    "\n",
    "\n",
    "# Learn the dictionary\n",
    "# D_clean ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uE4yTyzsQzb-"
   },
   "source": [
    "OMP denoising\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GjcuX3ifQz8k"
   },
   "outputs": [],
   "source": [
    "def omp_denoising(noisy_img, D, step, tau):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WeTv2cH2Q8My"
   },
   "source": [
    "Denoising using the learned dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izTArKuqQ8zG"
   },
   "outputs": [],
   "source": [
    "# set the threshold\n",
    "tau = 1.15 * p * sigma_noise\n",
    "\n",
    "# define the step (=p for non overlapping paches)\n",
    "STEP = 4  # STEP = 1 might be very time consuming, start with larger STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SPbxHnZJRFEi"
   },
   "source": [
    "Solve the four denoising problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7zpEcMTRHNa"
   },
   "outputs": [],
   "source": [
    "# Denoising with dictionary D_generic\n",
    "# img_hat_generic =\n",
    "\n",
    "# Denoising with dictionary D_diff\n",
    "# img_hat_diff =\n",
    "\n",
    "# Denoising with dictionary D_noisy\n",
    "# img_hat_noisy =\n",
    "\n",
    "# Denoising with dictionary D_clean\n",
    "# img_hat_clean ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PGdkd7VgRgzo"
   },
   "source": [
    "Visualize the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R42tSb7ORhTk"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(get_dictionary_img(D_generic), cmap=\"gray\")\n",
    "ax[0].set_title(\"Dictionary (Generic)\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# psnr_hat =\n",
    "\n",
    "ax[1].imshow(img_hat_general, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Denoised image, PSNR = {psnr_hat:.2f}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HE3On_JdRpIa"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(get_dictionary_img(D_diff), cmap=\"gray\")\n",
    "ax[0].set_title(\"Dictionary (From a different image)\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# psnr_hat =\n",
    "\n",
    "ax[1].imshow(img_hat_diff, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Denoised image, PSNR = {psnr_hat:.2f}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ggAh1ReERr-R"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(get_dictionary_img(D_noisy), cmap=\"gray\")\n",
    "ax[0].set_title(\"Dictionary (From the noisy image)\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# psnr_hat =\n",
    "\n",
    "ax[1].imshow(img_hat_noisy, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Denoised image, PSNR = {psnr_hat:.2f}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Y-bM9jORwCc"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(get_dictionary_img(D_clean), cmap=\"gray\")\n",
    "ax[0].set_title(\"Dictionary (from the clean image)\")\n",
    "ax[0].axis(\"off\")\n",
    "\n",
    "# psnr_hat =\n",
    "\n",
    "ax[1].imshow(img_hat_clean, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Denoised image, PSNR = {psnr_hat:.2f}\")\n",
    "ax[1].axis(\"off\")\n",
    "\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_processing_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
