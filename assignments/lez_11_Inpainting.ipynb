{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4OrCm2aFXhE"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKVyjdHyIvBa"
   },
   "outputs": [],
   "source": [
    "rootfolder = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NB1-MvmFsot"
   },
   "source": [
    "Useful function for plot a 2D dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M, N = D.shape\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    nnn = int(np.ceil(np.sqrt(N)))\n",
    "    bound = 2\n",
    "    img = np.ones((nnn * p + bound * (nnn - 1), nnn * p + bound * (nnn - 1)))\n",
    "    for i in range(N):\n",
    "        m = np.mod(i, nnn)\n",
    "        n = int((i - m) / nnn)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m : m + p, n : n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "elxPQr5jRssy"
   },
   "source": [
    "Define a function that implements the OMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HEEtx02YRxui"
   },
   "outputs": [],
   "source": [
    "def OMP(s, D, L, tau):\n",
    "    _, N = D.shape\n",
    "    r = s.copy()  # initial residual\n",
    "    omega = []  # support set\n",
    "    x_OMP = np.zeros(N)  # final sparse code\n",
    "\n",
    "    while len(omega) < L and np.linalg.norm(r) > tau:\n",
    "        # SWEEP STEP: compute correlations between residual and dictionary atoms\n",
    "        e = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            e[j] = np.abs(D[:, j].T @ r)\n",
    "\n",
    "        # find the column index with maximum correlation\n",
    "        jStar = np.argmax(e)\n",
    "\n",
    "        # UPDATE support set\n",
    "        if jStar not in omega:\n",
    "            omega.append(jStar)\n",
    "\n",
    "        # update coefficients using least squares\n",
    "        D_omega = D[:, omega]\n",
    "        a, _, _, _ = np.linalg.lstsq(D_omega, s, rcond=None)\n",
    "\n",
    "        # update residual\n",
    "        r = s - D_omega @ a\n",
    "\n",
    "    # construct full sparse vector\n",
    "    for i, idx in enumerate(omega):\n",
    "        x_OMP[idx] = a[i]\n",
    "\n",
    "    return x_OMP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XF0xLVZyGCBc"
   },
   "source": [
    "Load the image and rescale it in $[0,1]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JZXPMFW2F-W1"
   },
   "outputs": [],
   "source": [
    "img = imread(f\"{rootfolder}/data/peppers256.png\") / 255\n",
    "# img = imread(f'{rootfolder}/data/barbara.png') / 255\n",
    "# img = imread(f'{rootfolder}/data/Lena512.png') / 255\n",
    "\n",
    "imsz = img.shape\n",
    "\n",
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patch\n",
    "M = p**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBSmSG5GIPe"
   },
   "source": [
    "Corrupt the image with white gaussian noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1NfJRxKGKFu"
   },
   "outputs": [],
   "source": [
    "sigma_noise = 20 / 255\n",
    "noisy_img = img + np.random.normal(size=imsz) * sigma_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8U0eZbQLq9Ya"
   },
   "source": [
    "Percentage of removed pixel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wiHOm1NArBLd"
   },
   "outputs": [],
   "source": [
    "perc_of_removed_pixels = 0.25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nU0XD2fwrJTw"
   },
   "source": [
    "Arbitrarily remove pixels setting them to zero\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dj8cTidGrdpG"
   },
   "outputs": [],
   "source": [
    "# create a vector with all the indexes of the image\n",
    "idx = np.arange(img.size)\n",
    "\n",
    "# shuffle it and take the target percentage of indexes\n",
    "np.random.shuffle(idx)\n",
    "idx = idx[: int(perc_of_removed_pixels * img.size)]\n",
    "\n",
    "# the mask is 0 for the chosen idx, 1 elsewhere\n",
    "msk = np.ones(img.shape)\n",
    "msk.flat[idx] = 0\n",
    "\n",
    "# apply the mask: set to 0 some elements in the noisy image\n",
    "noisy_img *= msk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1zq_JGPeL"
   },
   "source": [
    "Compute the psnr of the noisy input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OtzbfA_GRIA"
   },
   "outputs": [],
   "source": [
    "psnr_noisy = 10 * np.log10(1**2 / np.mean((img - noisy_img) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMQ-c73WGT6f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Noisy image before inpainting, PSNR = {psnr_noisy:.2f}\")\n",
    "\n",
    "ax[1].imshow(msk, cmap=\"gray\")\n",
    "ax[1].set_title(\"Dead pixels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w7g7MvnnTTHT"
   },
   "source": [
    "Load and display the dictionary learned from patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgGdWipTTXW-"
   },
   "outputs": [],
   "source": [
    "D = loadmat(f\"{rootfolder}/data/dict_nat_img.mat\")[\"D\"]\n",
    "\n",
    "# add a constant atom to D, KSVD was trained over patches with zero mean - and normalize it\n",
    "# UPDATE D\n",
    "dc = np.ones((M, 1)) / np.sqrt(M)\n",
    "D = np.hstack([D, dc])\n",
    "D = D / np.linalg.norm(D, axis=0)\n",
    "\n",
    "# display the dictionary\n",
    "\n",
    "D_img = get_dictionary_img(D)\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(D_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6MOxJJOTuK1"
   },
   "source": [
    "## Inpainting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue9PsXb9Txk2"
   },
   "outputs": [],
   "source": [
    "# SET stopping criteria of OMP\n",
    "# orthogonal matching pursuit uses sparsity and errors as stopping criteria\n",
    "L = M / 2\n",
    "\n",
    "# initialize the estimated image\n",
    "img_hat = np.zeros_like(img)\n",
    "\n",
    "# initialize the weight matrix\n",
    "weights = np.zeros_like(img)\n",
    "\n",
    "# define the step (=p for non overlapping paches)\n",
    "STEP = 4  # STEP = 1 might be very time consuming, start with larger STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhGFrleuTzyn"
   },
   "source": [
    "Operate patchwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZV1qd-DT5vG"
   },
   "outputs": [],
   "source": [
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        # extract the patch with the top left corner at pixel (ii, jj)\n",
    "        s = noisy_img[i : i + p, j : j + p].reshape(-1, 1)\n",
    "\n",
    "        # patch extracted from the mask\n",
    "        m = msk[i : i + p, j : j + p].reshape(-1, 1)\n",
    "\n",
    "        # design the projection operator over the current patch\n",
    "        proj = np.diag(m.ravel())\n",
    "\n",
    "        # tau should be proportional to the number of pixels remaining in the patch\n",
    "        tau = 1e-3 * np.sqrt(np.sum(m))\n",
    "\n",
    "        # sparse coding w.r.t. PD the inpainted dictionary using L and tau as stopping criteria\n",
    "        PD = proj @ D\n",
    "        x = OMP(proj @ s, PD, L, tau)\n",
    "\n",
    "        # reconstruction: synthesis w.r.t. D the dictionary yielding sparse representation\n",
    "        s_hat = D @ x\n",
    "\n",
    "        # use uniform weights for aggregation\n",
    "        w = 1\n",
    "\n",
    "        # put the denoised patch into the estimated image using uniform weights\n",
    "        # UPDATE img_hat\n",
    "        img_hat[i : i + p, j : j + p] += w * s_hat.reshape(p, p)\n",
    "\n",
    "        # store the weight of the current patch in the weight matrix\n",
    "        # UPDATE weights\n",
    "        weights[i : i + p, j : j + p] += w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSc72uk8T-AS"
   },
   "source": [
    "Normalize the estimated image with the computed weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9Jsy1iYT_fJ"
   },
   "outputs": [],
   "source": [
    "img_hat = img_hat / weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ItjKLoIy1M"
   },
   "source": [
    "Compute the psnr of the estimated image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kXOFkvUldxFt"
   },
   "outputs": [],
   "source": [
    "psnr_hat = 10 * np.log10(1**2 / np.mean((img - img_hat) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuwTIEL3I1Ki"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Corrupted image, PSNR = {psnr_noisy:.2f}\")\n",
    "\n",
    "ax[2].imshow(img_hat, cmap=\"gray\")\n",
    "ax[2].set_title(f\"Estimated Image,\\nPSNR = {psnr_hat:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_processing_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
