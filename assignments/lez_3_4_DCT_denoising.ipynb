{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "opwp5eU9E-8f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fft import dct, idct\n",
    "from scipy.signal import convolve2d\n",
    "from skimage.io import imread\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N0H_uNYDFo9a"
   },
   "outputs": [],
   "source": [
    "rootfolder = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4kVu6DxV_UzG"
   },
   "source": [
    "# Denoising\n",
    "\n",
    "The goal of this section is to implement a simple denoising algorithm based on the 2D DCT. Given a noise free image $Y$, we observe a noisy version $S$:\n",
    "\n",
    "$$\n",
    "S = Y + \\eta\n",
    "$$\n",
    "\n",
    "where $\\eta\\sim N(0, \\sigma^2)$ denotes white Gaussian noise.\n",
    "\n",
    "Our goal is to compute an estimate $\\widehat Y$ of the original image $Y$. To evaluate the performance of the denoising algorithm we use again the PSNR:\n",
    "\n",
    "$$\n",
    "\\text{PSNR} = 10\\log_{10}\\frac{1}{\\text{MSE}(Y, \\widehat Y)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k6LEMyoWIO4u"
   },
   "source": [
    "## Synthetically corrupt an noisy image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq78PWSDFw7G"
   },
   "source": [
    "Load the image and rescale it in $[0,1]$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PHuWhKkwFdIR"
   },
   "outputs": [],
   "source": [
    "img = imread(f\"{rootfolder}/data/cameraman.png\") / 255  # /data/checkerboard.png\n",
    "imsz = img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBSmSG5GIPe"
   },
   "source": [
    "Corrupt the image with white gaussian noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m1NfJRxKGKFu"
   },
   "outputs": [],
   "source": [
    "sigma_noise = 20 / 255\n",
    "noisy_img = img + np.random.normal(size=imsz) * sigma_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1zq_JGPeL"
   },
   "source": [
    "Compute the psnr of the noisy input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9OtzbfA_GRIA"
   },
   "outputs": [],
   "source": [
    "psnr_noisy = 10 * np.log10(1 / np.mean((noisy_img - img) ** 2))\n",
    "psnr_noisy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oMQ-c73WGT6f"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Noisy image, PSNR = {psnr_noisy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iE35SOcaI9_a"
   },
   "source": [
    "## Noise estimation\n",
    "\n",
    "Compute the horizontal derivative of the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qtr03zyaJGwj"
   },
   "outputs": [],
   "source": [
    "differences = np.diff(noisy_img, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFZukTDTJI5R"
   },
   "source": [
    "Compute sigma as the empirical std\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0b_by0zJIkF"
   },
   "outputs": [],
   "source": [
    "sigma_hat_emp = np.std(differences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XR2FCd42JN1I"
   },
   "source": [
    "Use MAD to estimate the noise level sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cGzy3oZMJRDZ"
   },
   "outputs": [],
   "source": [
    "sigma_hat = np.median(np.abs(differences - np.median(differences))) / (\n",
    "    0.6745 * np.sqrt(2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YPV1F7lhJTB7"
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"sigma: {sigma_noise:.3f}, sigma_hat (empirical std): {sigma_hat_emp:.3f}, sigma_hat (MAD): {sigma_hat:.3f}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPeaH5JjIj3k"
   },
   "source": [
    "## Denoising by Smoothing\n",
    "\n",
    "Implement Denoising by Smoothing using convolution against a uniform filter of different size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D9S_vXelHrjS"
   },
   "outputs": [],
   "source": [
    "filter_size = 3\n",
    "\n",
    "filter = np.ones((filter_size, filter_size)) / (filter_size**2)\n",
    "\n",
    "# compute the convolution with convolve2d()\n",
    "img_hat_conv = convolve2d(noisy_img, filter, mode=\"same\", boundary=\"fill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "19PixqmEQDg6"
   },
   "outputs": [],
   "source": [
    "psnr_conv = 10 * np.log10(1 / np.mean((img_hat_conv - img) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvkRgSLJQbn9"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(20, 10))\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(img_hat_conv, cmap=\"gray\")\n",
    "ax[1].set_title(\n",
    "    f\"Image denoised by convolution (filter size: {filter_size}), PSNR = {psnr_conv:.2f}\"\n",
    ")\n",
    "\n",
    "ax[2].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[2].set_title(f\"Noisy image, PSNR = {psnr_noisy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7j9pcXTvFl_h"
   },
   "source": [
    "## Denoising by Leveraging Sparsity in the DCT Domain\n",
    "\n",
    "Definition of dct2 and idct2 (they are not builtin functions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u7PgrQa4Fkln"
   },
   "outputs": [],
   "source": [
    "def dct2(s):\n",
    "    return dct(dct(s.T, norm=\"ortho\").T, norm=\"ortho\")\n",
    "\n",
    "\n",
    "def idct2(x):\n",
    "    return idct(idct(x.T, norm=\"ortho\").T, norm=\"ortho\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J7xwDMFdJ0r4"
   },
   "outputs": [],
   "source": [
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patch\n",
    "M = p**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NB1-MvmFsot"
   },
   "source": [
    "Useful function for plot the 2D DCT dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M = D.shape[0]\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    bound = 2\n",
    "    img = np.ones((p * p + bound * (p - 1), p * p + bound * (p - 1)))\n",
    "    for i in range(M):\n",
    "        m = np.mod(i, p)\n",
    "        n = int((i - m) / p)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m : m + p, n : n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BxKnKExsH_Hb"
   },
   "source": [
    "## DCT denoising\n",
    "\n",
    "Generate the DCT basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bfxv8-RCIHMk"
   },
   "outputs": [],
   "source": [
    "D = np.zeros((M, M))\n",
    "cnt = 0\n",
    "for i in range(p):\n",
    "    for j in range(p):\n",
    "        basis = np.zeros((p, p))\n",
    "        basis[i, j] = 1\n",
    "        D[:, cnt] = idct2(basis).flatten()\n",
    "        cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9PB9UCS5II-J"
   },
   "outputs": [],
   "source": [
    "D_img = get_dictionary_img(D)\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(D_img, cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rEEitk8qIUeE"
   },
   "source": [
    "Denoising: set parameters and initialize the variables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hk2qJgl_ISwt"
   },
   "outputs": [],
   "source": [
    "# initialize the estimated image\n",
    "img_hat = np.zeros_like(img)\n",
    "\n",
    "# initialize the weight matrix\n",
    "weights = np.zeros_like(img)\n",
    "\n",
    "# set the threshold for the Hard Thresholding\n",
    "tau = 3 * sigma_noise  # Donoho says: sigma * sqrt(2*log(p^2))\n",
    "\n",
    "# define the step\n",
    "STEP = p // 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 with uniform weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4c2rIFvSIaUP"
   },
   "source": [
    "Perform the denoising patchwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hat_step8 = np.zeros_like(img)\n",
    "weights_step8 = np.zeros_like(img)\n",
    "\n",
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        s = noisy_img[i : i + p, j : j + p]\n",
    "        x = dct2(s)\n",
    "        x_HT = np.where(np.abs(x) < tau, 0, x)\n",
    "        x_HT[0, 0] = x[0, 0]\n",
    "        s_hat = idct2(x_HT)\n",
    "        w = 1.0\n",
    "        img_hat_step8[i : i + p, j : j + p] += w * s_hat\n",
    "        weights_step8[i : i + p, j : j + p] += w\n",
    "\n",
    "# Normalize the estimated image with the computed weights, i.e. compute averages\n",
    "img_hat_step8 = img_hat_step8 / (weights_step8 + 1e-8)\n",
    "# Compute PSNR\n",
    "psnr_step8 = 10 * np.log10(1 / np.mean((img_hat_step8 - img) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP = 1\n",
    "img_hat_step1_uniform = np.zeros_like(img)\n",
    "weights_step1_uniform = np.zeros_like(img)\n",
    "\n",
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        s = noisy_img[i : i + p, j : j + p]\n",
    "        x = dct2(s)\n",
    "        x_HT = np.where(np.abs(x) < tau, 0, x)\n",
    "        x_HT[0, 0] = x[0, 0]\n",
    "        s_hat = idct2(x_HT)\n",
    "        w = 1.0\n",
    "        img_hat_step1_uniform[i : i + p, j : j + p] += w * s_hat\n",
    "        weights_step1_uniform[i : i + p, j : j + p] += w\n",
    "\n",
    "img_hat_step1_uniform = img_hat_step1_uniform / (weights_step1_uniform + 1e-8)\n",
    "psnr_step1_uniform = 10 * np.log10(1 / np.mean((img_hat_step1_uniform - img) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step size 1 with sparsity-aware weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_hat_step1_sparse = np.zeros_like(img)\n",
    "weights_step1_sparse = np.zeros_like(img)\n",
    "\n",
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        s = noisy_img[i : i + p, j : j + p]\n",
    "        x = dct2(s)\n",
    "        x_HT = np.where(np.abs(x) < tau, 0, x)\n",
    "        x_HT[0, 0] = x[0, 0]\n",
    "        s_hat = idct2(x_HT)\n",
    "        # Sparsity-aware weight: number of non-zero coefficients after thresholding\n",
    "        w = np.sum(x_HT != 0) / M\n",
    "        img_hat_step1_sparse[i : i + p, j : j + p] += w * s_hat\n",
    "        weights_step1_sparse[i : i + p, j : j + p] += w\n",
    "\n",
    "img_hat_step1_sparse = img_hat_step1_sparse / (weights_step1_sparse + 1e-8)\n",
    "psnr_step1_sparse = 10 * np.log10(1 / np.mean((img_hat_step1_sparse - img) ** 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 6))\n",
    "\n",
    "ax[0].imshow(img_hat_step8, cmap=\"gray\")\n",
    "ax[0].set_title(f\"Estimated Image (step: 8), PSNR = {psnr_step8:.2f}\")\n",
    "\n",
    "ax[1].imshow(img_hat_step1_uniform, cmap=\"gray\")\n",
    "ax[1].set_title(\n",
    "    f\"Estimated Image (step: 1) with Uniform weights, PSNR = {psnr_step1_uniform:.2f}\"\n",
    ")\n",
    "\n",
    "ax[2].imshow(img_hat_step1_sparse, cmap=\"gray\")\n",
    "ax[2].set_title(\n",
    "    f\"Estimated Image (step: 1) with Sparsity-aware weights, PSNR = {psnr_step1_sparse:.2f}\"\n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXCFm_QELxMV"
   },
   "source": [
    "## Wiener Filtering\n",
    "\n",
    "Initialize the estimated image via Wiener Filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pHDDWn4kLyIM"
   },
   "outputs": [],
   "source": [
    "img_hat_wiener = np.zeros_like(img)\n",
    "weights = np.zeros_like(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TE3_wtU7L2EQ"
   },
   "source": [
    "Perform the denoising patch wise by wiener filtering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U8dvgcTgL_jr"
   },
   "outputs": [],
   "source": [
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        # extract the patch from the noisy image with the top left corner at pixel (ii, jj)\n",
    "        s = noisy_img[i : i + p, j : j + p]\n",
    "\n",
    "        # compute the representation w.r.t. the 2D DCT dictionary\n",
    "        x = dct2(s)\n",
    "\n",
    "        # extract the patch from the image estimated by HT with the top left corner at pixel (ii, jj)\n",
    "        s_hat_HT = img_hat_step1_sparse[i : i + p, j : j + p]\n",
    "\n",
    "        # perform the Wiener filtering (do not filter the DC!)\n",
    "        x_hat_HT = dct2(s_hat_HT)\n",
    "        x_wie = x.copy()\n",
    "        x_wie[1:, :] = (\n",
    "            x_hat_HT[1:, :] ** 2 / (x_hat_HT[1:, :] ** 2 + sigma_noise**2)\n",
    "        ) * x[1:, :]\n",
    "        x_wie[:, 1:] = (\n",
    "            x_hat_HT[:, 1:] ** 2 / (x_hat_HT[:, 1:] ** 2 + sigma_noise**2)\n",
    "        ) * x[:, 1:]\n",
    "\n",
    "        # perform the reconstruction\n",
    "        s_hat_wie = idct2(x_wie)\n",
    "\n",
    "        # use uniform weights to aggregate the multiple estimates\n",
    "        w = 1\n",
    "\n",
    "        # put the denoised patch into the denoised image using the computed weight\n",
    "        img_hat_wiener[i : i + p, j : j + p] += w * s_hat_wie\n",
    "\n",
    "        # store the weight of the current patch in the weight matrix\n",
    "        weights[i : i + p, j : j + p] += w\n",
    "\n",
    "# Normalize the estimated image with the computed weights\n",
    "img_hat_wiener = img_hat_wiener / (weights + 1e-8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cmZqMLNMJDU4"
   },
   "source": [
    "Compute the PSNR of the two estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-8t1vvHJDU4"
   },
   "outputs": [],
   "source": [
    "psnr_wiener = 10 * np.log10(1 / np.mean((img_hat_wiener - img) ** 2))\n",
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img_hat_step1_uniform, cmap=\"gray\")\n",
    "ax[0].set_title(f\"HT Estimate, PSNR = {psnr_step1_uniform:.2f}\")\n",
    "\n",
    "ax[1].imshow(img_hat_wiener, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Wiener Estimate, PSNR = {psnr_wiener:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Image_processing_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
