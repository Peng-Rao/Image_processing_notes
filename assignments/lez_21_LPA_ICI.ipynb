{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "quAd5kUJXS2h"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.signal import convolve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9KEr7OUZ00l"
   },
   "source": [
    "Define the function to compute the kernel given the weights and the degree of the polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ig2s_rwtZx6P"
   },
   "outputs": [],
   "source": [
    "def compute_LPA_kernel(w, N):\n",
    "    # compute the LPA kernel for a given weights and polynomial degree\n",
    "    # input:\n",
    "    #   w: vector containing the weights for the local LS problem\n",
    "    #   N: degree of the polynomial approximation\n",
    "    # return:\n",
    "    #   g: the computed LPA kernel\n",
    "\n",
    "    return g\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "34S3SYMckqtD"
   },
   "source": [
    "LPA-ICI\n",
    "-------\n",
    "Set the LPA-ICI parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yYPg7PvuaT9Y"
   },
   "outputs": [],
   "source": [
    "# maximum degree of polynomial used for fitting\n",
    "N = 5\n",
    "\n",
    "# parameter for the confidence intervals in the ICI rule\n",
    "Gamma = 2\n",
    "\n",
    "# Set all the scale values\n",
    "hmax = 51\n",
    "all_h = np.arange(1, hmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVZHR5NbaKNZ"
   },
   "source": [
    "Generate the signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IlgyMA_SaMZz"
   },
   "outputs": [],
   "source": [
    "LENGTH = 1000\n",
    "\n",
    "ty = np.linspace(0, 1, LENGTH)\n",
    "y = np.sin(2 / (ty + 0.05))\n",
    "\n",
    "#  noise standard deviation\n",
    "sigma = 0.2\n",
    "\n",
    "# noisy signal\n",
    "s = y + sigma*np.random.normal(size=LENGTH)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ty, s, 'r.')\n",
    "plt.plot(ty, y, 'k--', linewidth=2)\n",
    "plt.grid()\n",
    "plt.legend(['noisy', 'original'])\n",
    "plt.title('Input Signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMZBeqQtcunJ"
   },
   "source": [
    "Generate the LPA kernels for all the scale. Use centered weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qUUogpW_qmdi"
   },
   "outputs": [],
   "source": [
    "all_g = []\n",
    "for i in range(len(all_h)):\n",
    "    # define the weights for the scale h (symmetric, left or right)\n",
    "    # w =\n",
    "\n",
    "    # compute and store the kernel g\n",
    "    # TODO: implement the function compute_LPA_kernel\n",
    "    g = compute_LPA_kernel(w, N)\n",
    "\n",
    "    all_g.append(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fBP6KA27s_kF"
   },
   "source": [
    "Initialize all the variables for the ICI rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "23d65QPcrRso"
   },
   "outputs": [],
   "source": [
    "# initialize the estimate\n",
    "# yhat =\n",
    "\n",
    "# initialize the vector containing the best scale for each sample\n",
    "# best_scale =\n",
    "\n",
    "# initialize the lower and upper bound vectors\n",
    "# lower_bounds =\n",
    "# upper_bounds ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AaCGFuCrlbGI"
   },
   "source": [
    "Loop over all the scales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5nuG5GihlgQ3"
   },
   "outputs": [],
   "source": [
    "for i, h in enumerate(all_h):\n",
    "    g = all_g[i]\n",
    "\n",
    "    # compute the estimate for the scale h\n",
    "#    yhat_h =\n",
    "\n",
    "    # compute the lower and upper bound of the confidence interval for the scale h\n",
    "#    lb =\n",
    "#    ub =\n",
    "\n",
    "    # update the lower and upper bounds\n",
    "#    lower_bounds =\n",
    "#    upper_bounds =\n",
    "\n",
    "    # identify for which samples h is the best scale according to the\n",
    "    # ICI rule and update the best_scale vector accordingly\n",
    "#    best_scale\n",
    "\n",
    "    # update the estimate\n",
    "    # yhat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dVx-E5q8tCs3"
   },
   "source": [
    "Use the best scale for each sample to compute the final estimates\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GHi9A8uXqryE"
   },
   "outputs": [],
   "source": [
    "# yhat_final ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tBJUSUuqdp7v"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(2, 1, figsize = (12,7))\n",
    "ax[0].plot(ty, s, 'r.')\n",
    "ax[0].plot(ty, y, 'k--', linewidth=3)\n",
    "ax[0].plot(ty, yhat_final, 'm-', linewidth=3, color = 'blue')\n",
    "ax[0].grid()\n",
    "ax[0].legend(['noisy', 'original', 'LPA-ICI estimate'])\n",
    "ax[0].set_title(f'N = {N:d}')\n",
    "\n",
    "ax[1].plot(ty, best_scale, 'r.')\n",
    "ax[1].set_title('Scale selected by ICI rule')\n",
    "ax[1].grid()\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kMvwf8ram7Lf"
   },
   "source": [
    "LPA-ICI with Aggregation\n",
    "------------------------\n",
    "Set the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZtsjdjSWnENQ"
   },
   "outputs": [],
   "source": [
    "# maximum degree of polynomial used for fitting\n",
    "N = 1\n",
    "\n",
    "# parameter for the confidence intervals in the ICI rule\n",
    "Gamma = 2\n",
    "\n",
    "# Set all the scale values\n",
    "hmax = 51\n",
    "all_h = np.arange(1, hmax+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YXG1JzYknKLl"
   },
   "source": [
    "Generate synthetic signal signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vfp46DzKnMMq"
   },
   "outputs": [],
   "source": [
    "LENGTH = 1000\n",
    "ty = np.linspace(0, 1, LENGTH)\n",
    "y = 8 * ty ** 2 - 2*ty + 2\n",
    "y[ty >0.5] = y[ty >0.5] + 7\n",
    "\n",
    "#  noise standard deviation\n",
    "sigma = 0.3\n",
    "\n",
    "# noisy signal\n",
    "s = y + sigma*np.random.normal(size=LENGTH)\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(ty, s, 'r.')\n",
    "plt.plot(ty, y, 'k--', linewidth=2)\n",
    "plt.grid()\n",
    "plt.legend(['noisy', 'original'])\n",
    "plt.title('Input Signal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tfg3XYvInP9p"
   },
   "source": [
    "Generate the LPA kernels for all the scale for both left and right windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oy5unf_onSWi"
   },
   "outputs": [],
   "source": [
    "all_g_left = []\n",
    "all_g_right = []\n",
    "\n",
    "for i, h in enumerate(all_h):\n",
    "    # define the weights for the scale h (left)\n",
    "#    w =\n",
    "    g_left = compute_LPA_kernel(w, N)\n",
    "    all_g_left.append(g_left)\n",
    "\n",
    "    # define the weights for the scale h (right)\n",
    "#    w =\n",
    "    g_right = compute_LPA_kernel(w, N)\n",
    "    all_g_right.append(g_right)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPapyBO_oFEj"
   },
   "source": [
    "Use the LPA-ICI to compute the estimate based on the **left** kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pNrjeHXOoRbo"
   },
   "outputs": [],
   "source": [
    "# initialize the left estimate\n",
    "# yhat_left =\n",
    "\n",
    "# initialize the lower and upper bound vectors\n",
    "# lower_bounds =\n",
    "# upper_bounds =\n",
    "\n",
    "# intialize the vector containing the variance of the estimator for each sample\n",
    "# var_left =\n",
    "\n",
    "for i, h in enumerate(all_h):\n",
    "    g = all_g_left[i]\n",
    "\n",
    "    # compute the estimate for the scale h\n",
    "#    yhat_h =\n",
    "\n",
    "    # compute the lower and upper bound of the confidence interval for the scale h\n",
    "#    lb =\n",
    "#    ub =\n",
    "\n",
    "    # update the lower and upper bounds\n",
    "#    lower_bounds =\n",
    "#    upper_bounds =\n",
    "\n",
    "    # update the estimate\n",
    "#   yhat_left\n",
    "\n",
    "    # update the variance\n",
    "#   var_left"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iai8z6xLolaw"
   },
   "source": [
    "Use the LPA-ICI to compute the estimate based on the **right** kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K7vfQJb9ola4"
   },
   "outputs": [],
   "source": [
    "# initialize the right estimate\n",
    "# yhat_right =\n",
    "\n",
    "# initialize the lower and upper bound vectors\n",
    "# lower_bounds =\n",
    "# upper_bounds =\n",
    "\n",
    "# intialize the vector containing the variance of the estimator for each sample\n",
    "# var_right =\n",
    "\n",
    "for i, h in enumerate(all_h):\n",
    "    g = all_g_left[i]\n",
    "\n",
    "    # compute the estimate for the scale h\n",
    "#    yhat_h =\n",
    "\n",
    "    # compute the lower and upper bound of the confidence interval for the scale h\n",
    "#    lb =\n",
    "#    ub =\n",
    "\n",
    "    # update the lower and upper bounds\n",
    "#    lower_bounds =\n",
    "#    upper_bounds =\n",
    "\n",
    "    # update the estimate\n",
    "#   yhat_right\n",
    "\n",
    "    # update the variance\n",
    "#   var_right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CSVwLUp8pFm4"
   },
   "source": [
    "Perform the aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jpw96MPppJL6"
   },
   "outputs": [],
   "source": [
    "# yhat_aggr ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UlIPoQuvqH5v"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(ty, s, 'r.')\n",
    "plt.plot(ty, y, 'k--', linewidth=3)\n",
    "plt.plot(ty, yhat_right, 'm-', linewidth=3)\n",
    "plt.plot(ty, yhat_left, 'g-', linewidth=3)\n",
    "plt.plot(ty, yhat_aggr, 'b-', linewidth=3)\n",
    "plt.grid()\n",
    "plt.legend(['noisy', 'original', 'right estimate', 'left estimate', 'aggregated estimate'])\n",
    "plt.title(f'N = {N:d}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNb3zFnnetv90zpaqEpgLju",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
