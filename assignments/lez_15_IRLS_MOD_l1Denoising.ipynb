{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4OrCm2aFXhE"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.io import loadmat\n",
    "from skimage.io import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKVyjdHyIvBa"
   },
   "outputs": [],
   "source": [
    "rootfolder = \"..\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be43ir2EHcSE"
   },
   "source": [
    "## IRLS Algorithm\n",
    "\n",
    "Define the problem parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Sh4rbXeHh_E"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 3], [3, 1]])  # low dimensions to plot it, you can test larger sizes\n",
    "b = np.array([-1, 2])\n",
    "\n",
    "lmbda = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjOQIg-ZHpTc"
   },
   "source": [
    "The function to be minimized is $\\frac{1}{2}\\|Ax-b\\|_2^2 + \\lambda \\|x\\|_1$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IZ3t2qiHoOY"
   },
   "outputs": [],
   "source": [
    "f = lambda x: 0.5 * np.sum((A @ x - b) ** 2) + lmbda * np.sum(np.abs(x))\n",
    "\n",
    "# derivative of f from matrix calculus\n",
    "df = lambda x: A.T @ (A @ x) - A.T @ b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjmesSGYH4YK"
   },
   "source": [
    "Plot the function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXdKkXicH8-8"
   },
   "outputs": [],
   "source": [
    "# this function has been prepared only for the visualization sake, no need to go through this but it renders some nice\n",
    "# graphics :)\n",
    "F = (\n",
    "    lambda r1, r2: (r1 * A[0, 0] + r2 * A[0, 1] - b[0]) ** 2\n",
    "    + (r1 * A[1, 0] + r2 * A[1, 1] - b[1]) ** 2\n",
    "    + lmbda * (np.abs(r1) + np.abs(r2))\n",
    ")\n",
    "xx, yy = np.meshgrid(np.arange(-10, 10, 1), np.arange(-10, 10, 1))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ8eKBxUayEV"
   },
   "source": [
    "Set the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcqIs0rxayEW"
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 1e3\n",
    "TOL_DIST_X = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J3HwecVayEX"
   },
   "source": [
    "Initialization: test different inizializations, the function is convex, you always converge to the same solution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otG86BH8ayEX"
   },
   "outputs": [],
   "source": [
    "x0 = np.array([5, -10])\n",
    "\n",
    "# initialization\n",
    "all_x = [x0]\n",
    "distanceX = 1e10  # stopping criteria\n",
    "cnt = 0\n",
    "delta = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t-ozDQvayEY"
   },
   "source": [
    "Main loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a49h-zsayEY"
   },
   "outputs": [],
   "source": [
    "while cnt < MAX_ITER and distanceX > TOL_DIST_X:\n",
    "    x = all_x[-1]\n",
    "\n",
    "    # compute the weight matrix\n",
    "    W = np.diag(1 / (np.abs(x) + delta))\n",
    "\n",
    "    # solve the weighted regularized LS system\n",
    "    # (A^T A + lambda * W) x = A^T b\n",
    "    x_current = np.linalg.solve(A.T @ A + lmbda * W, A.T @ b)\n",
    "\n",
    "    # compute distance between consecutive iterates\n",
    "    distanceX = np.linalg.norm(x_current - x)\n",
    "\n",
    "    # store the estimate\n",
    "    all_x.append(x_current.copy())\n",
    "\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNNKjaJmayEY"
   },
   "source": [
    "Plot all the estimates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3NrMKd3ayEZ"
   },
   "outputs": [],
   "source": [
    "# plot the new estimate\n",
    "xxplot = [x[0] for x in all_x]\n",
    "yyplot = [x[1] for x in all_x]\n",
    "zzplot = F(np.array(xxplot), np.array(yyplot))\n",
    "\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes(projection=\"3d\")\n",
    "ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])\n",
    "ax.plot3D(xxplot, yyplot, zzplot, \"r-o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNFvIs7uayEa"
   },
   "outputs": [],
   "source": [
    "print(f\"nr of iteration of IRLS (before stopping criteria met): {cnt}\\n\")\n",
    "print(f\"Solution of IRLS: [{x_current[0]:.4f}, {x_current[1]:.4f}]\\n\")\n",
    "print(f\"Value of the functional: {f(x_current):.4f}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1g68tnc6uoK"
   },
   "source": [
    "## **THIS WAS NOT PRESENTED IN THE 2025 EDITION**: MOD dictionary learning\n",
    "\n",
    "Useful function for plot the 2D DCT dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M, N = D.shape\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    nnn = int(np.ceil(np.sqrt(N)))\n",
    "    bound = 2\n",
    "    img = np.ones((nnn * p + bound * (nnn - 1), nnn * p + bound * (nnn - 1)))\n",
    "    for i in range(N):\n",
    "        m = np.mod(i, nnn)\n",
    "        n = int((i - m) / nnn)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m : m + p, n : n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BptBSuNQ64ak"
   },
   "source": [
    "Define a function to perform the sparse coding using your favorite algorithm (IRLS, FISTA or ISTA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MDlsdgp68Ci"
   },
   "outputs": [],
   "source": [
    "def IRLS(s, D, lmbda, x0=None):\n",
    "    # Parameters\n",
    "    MAX_ITER = 100\n",
    "    TOL_DIST_X = 1e-6\n",
    "    delta = 1e-6\n",
    "\n",
    "    # Initialize\n",
    "    if x0 is None:\n",
    "        x = np.zeros(D.shape[1])\n",
    "    else:\n",
    "        x = x0.copy()\n",
    "\n",
    "    distanceX = 1e10\n",
    "    cnt = 0\n",
    "\n",
    "    while cnt < MAX_ITER and distanceX > TOL_DIST_X:\n",
    "        # Store previous x for distance calculation\n",
    "        x_prev = x.copy()\n",
    "\n",
    "        # Compute the weight matrix\n",
    "        W = np.diag(1 / (np.abs(x) + delta))\n",
    "\n",
    "        # Solve the weighted regularized LS system\n",
    "        # (D^T D + lambda * W) x = D^T s\n",
    "        x = np.linalg.solve(D.T @ D + lmbda * W, D.T @ s)\n",
    "\n",
    "        # Compute distance between consecutive iterates\n",
    "        distanceX = np.linalg.norm(x - x_prev)\n",
    "\n",
    "        cnt += 1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVoq64RP6-kk"
   },
   "source": [
    "Load the image and rescale it in [0,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRItOr027BVK"
   },
   "outputs": [],
   "source": [
    "img = imread(f\"{rootfolder}/data/barbara.png\") / 255\n",
    "imsz = img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS9awY-77EeL"
   },
   "source": [
    "Set the parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oii0m41f7F26"
   },
   "outputs": [],
   "source": [
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patchfrom skimage.io import imread\n",
    "M = p**2\n",
    "\n",
    "# number of columns in the dictionary\n",
    "N = 96\n",
    "\n",
    "# extract the random patches from the noisy image\n",
    "npatch = 1000\n",
    "\n",
    "# only few MOD iterations are needed for a good dictionary\n",
    "max_iter = 10\n",
    "\n",
    "lmbda = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwKu4JL87Je2"
   },
   "source": [
    "Extract $npatch$ random patches from the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgXVqGNl7Ttq"
   },
   "outputs": [],
   "source": [
    "S = np.zeros((M, npatch))\n",
    "for n in range(npatch):\n",
    "    # Generate random coordinates\n",
    "    i = np.random.randint(0, imsz[0] - p + 1)\n",
    "    j = np.random.randint(0, imsz[1] - p + 1)\n",
    "    # Extract patch and vectorize it\n",
    "    patch = img[i : i + p, j : j + p]\n",
    "    S[:, n] = patch.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynOk7uYr7cvU"
   },
   "source": [
    "Initialize the dictionary randomly and the normalize the columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrkaVUCO7fgt"
   },
   "outputs": [],
   "source": [
    "D = np.random.randn(M, N)\n",
    "# Normalize columns to unit norm\n",
    "D = D / np.linalg.norm(D, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZltkicV7iht"
   },
   "source": [
    "Initialize a matrix for the coefficients of all the patches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzj2vAn77nwc"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((N, npatch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJx4qIsh7oSj"
   },
   "source": [
    "Main loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z8XQNrG7qLQ"
   },
   "outputs": [],
   "source": [
    "for iter in range(max_iter):\n",
    "    # perform the sparse coding for all the patches in S\n",
    "    for n in range(npatch):\n",
    "        s = S[:, n]\n",
    "        x = IRLS(s, D, lmbda)\n",
    "        X[:, n] = x\n",
    "\n",
    "    # MOD update: solve D = S * X^T * (X * X^T)^(-1)\n",
    "    D = S @ X.T @ np.linalg.pinv(X @ X.T)\n",
    "\n",
    "    # normalize the columns\n",
    "    D = D / np.linalg.norm(D, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZGaziVS7rdn"
   },
   "source": [
    "Show the dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqHV9pHR7saw"
   },
   "outputs": [],
   "source": [
    "img_dict = get_dictionary_img(D)\n",
    "plt.figure()\n",
    "plt.imshow(img_dict, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luYMvFoa7wOp"
   },
   "source": [
    "## Denoising via $\\ell^1$ sparse coding (use a dictionary learned by KSVD)\n",
    "\n",
    "Set the noise level and add the noise to the original image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JBB5ylJ71HE"
   },
   "outputs": [],
   "source": [
    "sigma_noise = 20 / 255\n",
    "noisy_img = img + np.random.normal(size=imsz) * sigma_noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7HK4Qlr8Hqa"
   },
   "source": [
    "Compue the psnr of the noisy input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTO-fkTj8FwJ"
   },
   "outputs": [],
   "source": [
    "# Compute PSNR of noisy input\n",
    "psnr_noisy = 10 * np.log10(1 / np.mean((noisy_img - img) ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4k9TAEv8OqK"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img, cmap=\"gray\")\n",
    "ax[0].set_title(\"Original image\")\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap=\"gray\")\n",
    "ax[1].set_title(f\"Noisy image, PSNR = {psnr_noisy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gEUzAQJ8Qv0"
   },
   "source": [
    "Use the dictionary computed with the MOD or load a pretrained dictionary $D$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OMP(s, D, L, tau):\n",
    "    _, N = D.shape\n",
    "    r = s.copy()  # initial residual\n",
    "    omega = []  # support set\n",
    "    x_OMP = np.zeros(N)  # final sparse code\n",
    "\n",
    "    while len(omega) < L and np.linalg.norm(r) > tau:\n",
    "        # SWEEP STEP: compute correlations between residual and dictionary atoms\n",
    "        e = np.zeros(N)\n",
    "        for j in range(N):\n",
    "            e[j] = D[:, j].T @ r\n",
    "\n",
    "        # find the column index with maximum correlation\n",
    "        jStar = np.argmax(np.abs(e))\n",
    "\n",
    "        # UPDATE support set\n",
    "        if jStar not in omega:\n",
    "            omega.append(jStar)\n",
    "\n",
    "        # update coefficients using least squares\n",
    "        D_omega = D[:, omega]\n",
    "        x_omega, _, _, _ = np.linalg.lstsq(D_omega, s, rcond=None)\n",
    "\n",
    "        # update residual\n",
    "        r = s - D_omega @ x_omega\n",
    "\n",
    "    # construct full sparse vector\n",
    "    for i, idx in enumerate(omega):\n",
    "        x_OMP[idx] = x_omega[i]\n",
    "\n",
    "    return x_OMP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ksvd(S, M, N, max_iter, npatch, L, print_time=False):\n",
    "    # initialize the dictionary\n",
    "    D = np.random.randn(M, N)\n",
    "\n",
    "    # normalize each column of D (zero mean and unit norm)\n",
    "    # UPDATE D\n",
    "    D = D - np.mean(D, axis=0, keepdims=True)\n",
    "    D = D / np.linalg.norm(D, axis=0, keepdims=True)\n",
    "\n",
    "    # initialize the coefficient matrix\n",
    "    X = np.zeros((N, npatch))\n",
    "\n",
    "    # Main KSVD loop\n",
    "    for iter in range(max_iter):\n",
    "        time_start = time.time()\n",
    "\n",
    "        # Sparse coding step\n",
    "        # perform the sparse coding via OMP of all the columns of S\n",
    "        for n in range(npatch):\n",
    "            X[:, n] = OMP(S[:, n], D, L, 1e-6)\n",
    "\n",
    "        # Dictionary update step\n",
    "        # iterate over the columns of D\n",
    "        for j in range(N):\n",
    "            # find which signals uses the j-th atom in the sparse coding\n",
    "            omega = np.where(X[j, :] != 0)[0]\n",
    "\n",
    "            if len(omega) == 0:\n",
    "                # if the atom is never used then ignore or substitute it with a random vector\n",
    "                D[:, j] = np.random.randn(M)\n",
    "                D[:, j] = D[:, j] / np.linalg.norm(D[:, j])\n",
    "            else:\n",
    "                # compute the residual matrix E, ignoring the j-th atom\n",
    "                E = S - D @ X + np.outer(D[:, j], X[j, :])\n",
    "\n",
    "                # restrict E to the columns indicated by omega\n",
    "                Eomega = E[:, omega]\n",
    "\n",
    "                # Compute the best rank-1 approximation\n",
    "                U, Sigma, Vt = np.linalg.svd(Eomega, full_matrices=False)\n",
    "\n",
    "                # update the dictionary\n",
    "                D[:, j] = U[:, 0]\n",
    "\n",
    "                # update the coefficient matrix\n",
    "                X[j, omega] = Sigma[0] * Vt[0, :]\n",
    "\n",
    "        time_end = time.time()\n",
    "        if print_time:\n",
    "            print(f\"Iteration {iter} runtime: {time_end - time_start}\")\n",
    "\n",
    "    return D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1rO7pMs8ZHM"
   },
   "outputs": [],
   "source": [
    "D = loadmat(f\"{rootfolder}/data/dict_nat_img.mat\")[\"D\"]\n",
    "\n",
    "# show the dictionary\n",
    "D_img = get_dictionary_img(D)\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(D_img, cmap=\"gray\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue9PsXb9Txk2"
   },
   "outputs": [],
   "source": [
    "# initialize the estimated image\n",
    "img_hat = np.zeros_like(img)\n",
    "\n",
    "# initialize the weight matrix\n",
    "weights = np.zeros_like(img)\n",
    "\n",
    "# set the threshold\n",
    "tau = 2.2\n",
    "lmbda = tau * sigma_noise\n",
    "\n",
    "# define the step (=p for non overlapping paches)\n",
    "STEP = 4  # STEP = 1 might be very time consuming, start with larger STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhGFrleuTzyn"
   },
   "source": [
    "Operate patchwise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZV1qd-DT5vG"
   },
   "outputs": [],
   "source": [
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        # extract the patch with the top left corner at pixel (i, j)\n",
    "        s = noisy_img[i : i + p, j : j + p].flatten()\n",
    "\n",
    "        # store and subtract the mean\n",
    "        s_mean = np.mean(s)\n",
    "        s = s - s_mean\n",
    "\n",
    "        # perform the sparse coding of the patch s to compute the coefficients vector x\n",
    "        x = IRLS(s, D, lmbda)\n",
    "\n",
    "        # perform the reconstruction\n",
    "        s_hat = D @ x\n",
    "\n",
    "        w = 1\n",
    "\n",
    "        # add back the mean\n",
    "        s_hat = s_hat + s_mean\n",
    "\n",
    "        # put the denoised patch into the estimated image using uniform weights\n",
    "        img_hat[i : i + p, j : j + p] += w * s_hat.reshape((p, p))\n",
    "\n",
    "        # store the weight of the current patch in the weight matrix\n",
    "        weights[i : i + p, j : j + p] += w"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSc72uk8T-AS"
   },
   "source": [
    "Normalize the estimated image with the computed weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9Jsy1iYT_fJ"
   },
   "outputs": [],
   "source": [
    "img_hat = img_hat / (weights + 1e-10)  # Add small epsilon to avoid division by zero"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ItjKLoIy1M"
   },
   "source": [
    "Compute the psnr of the estimated image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuwTIEL3I1Ki"
   },
   "outputs": [],
   "source": [
    "psnr_hat = 10 * np.log10(1 / np.mean((img - img_hat) ** 2))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(img_hat, cmap=\"gray\")\n",
    "plt.title(f\"Estimated Image,\\nPSNR = {psnr_hat:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_processing_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
