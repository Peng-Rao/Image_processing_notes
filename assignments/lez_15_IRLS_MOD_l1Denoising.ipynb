{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z4OrCm2aFXhE"
   },
   "outputs": [],
   "source": [
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VKVyjdHyIvBa"
   },
   "outputs": [],
   "source": [
    "rootfolder = '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Be43ir2EHcSE"
   },
   "source": [
    "IRLS Algorithm\n",
    "--------------\n",
    "Define the problem parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8Sh4rbXeHh_E"
   },
   "outputs": [],
   "source": [
    "A = np.array([[1, 3], [3, 1]]) # low dimensions to plot it, you can test larger sizes\n",
    "b = np.array([-1, 2])\n",
    "\n",
    "lmbda = 0.5\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qjOQIg-ZHpTc"
   },
   "source": [
    "The function to be minimized is $\\frac{1}{2}\\|Ax-b\\|_2^2 + \\lambda \\|x\\|_1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-IZ3t2qiHoOY"
   },
   "outputs": [],
   "source": [
    "f = lambda x: 0.5 * np.sum((A @ x - b) ** 2) + lmbda * np.sum(np.abs(x))\n",
    "\n",
    "# derivative of f from matrix calculus\n",
    "df = lambda x: A.T @ (A @ x) - A.T @ b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjmesSGYH4YK"
   },
   "source": [
    "Plot the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NXdKkXicH8-8"
   },
   "outputs": [],
   "source": [
    "# this function has been prepared only for the visualization sake, no need to go through this but it renders some nice\n",
    "# graphics :)\n",
    "F = lambda r1, r2: (r1 * A[0, 0] + r2 * A[0, 1] - b[0]) ** 2 + (r1 * A[1, 0] + r2 * A[1,1] - b[1]) ** 2 + lmbda * (np.abs(r1) + np.abs(r2))\n",
    "xx, yy = np.meshgrid(np.arange(-10, 10, 1), np.arange(-10, 10, 1))\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJ8eKBxUayEV"
   },
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WcqIs0rxayEW"
   },
   "outputs": [],
   "source": [
    "MAX_ITER = 1e3\n",
    "TOL_DIST_X = 1e-10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5J3HwecVayEX"
   },
   "source": [
    "Initialization: test different inizializations, the function is convex, you always converge to the same solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "otG86BH8ayEX"
   },
   "outputs": [],
   "source": [
    "x0 = np.array([5, -10])\n",
    "\n",
    "# initialization\n",
    "all_x = [x0]\n",
    "distanceX = 1e10  # stopping criteria\n",
    "cnt = 0\n",
    "delta = 1e-6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_t-ozDQvayEY"
   },
   "source": [
    "Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5a49h-zsayEY"
   },
   "outputs": [],
   "source": [
    "while cnt < MAX_ITER and distanceX > TOL_DIST_X:\n",
    "    x = all_x[-1]\n",
    "\n",
    "    # compute the weight matrix\n",
    "    # W =\n",
    "\n",
    "    # solve the weighted regularized LS system\n",
    "    # x_current =\n",
    "\n",
    "    # distanceX =\n",
    "\n",
    "    # store the estimate\n",
    "    # update all_x\n",
    "\n",
    "    cnt = cnt + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BNNKjaJmayEY"
   },
   "source": [
    "Plot all the estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s3NrMKd3ayEZ"
   },
   "outputs": [],
   "source": [
    "# plot the new estimate\n",
    "xxplot = [x[0] for x in all_x]\n",
    "yyplot = [x[1] for x in all_x]\n",
    "zzplot = F(np.array(xxplot), np.array(yyplot))\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.plot_surface(xx, yy, F(xx, yy), edgecolor=[0, 0, 1], alpha=0.5, facecolor=[0, 1, 1])\n",
    "ax.plot3D(xxplot, yyplot, zzplot, 'r-o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yNFvIs7uayEa"
   },
   "outputs": [],
   "source": [
    "print(f'nr of iteration of IRLS (before stopping criteria met): {cnt}\\n')\n",
    "print(f'Solution of IRLS: [{x_current[0]:.4f}, {x_current[1]:.4f}]\\n')\n",
    "print(f'Value of the functional: {f(x_current):.4f}\\n')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1g68tnc6uoK"
   },
   "source": [
    "**THIS WAS NOT PRESENTED IN THE 2025 EDITION**: MOD dictionary learning\n",
    "-----------------------\n",
    "Useful function for plot the 2D DCT dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rey7kIlUF22r"
   },
   "outputs": [],
   "source": [
    "def get_dictionary_img(D):\n",
    "    M, N = D.shape\n",
    "    p = int(round(np.sqrt(M)))\n",
    "    nnn = int(np.ceil(np.sqrt(N)))\n",
    "    bound = 2\n",
    "    img = np.ones((nnn*p+bound*(nnn-1), nnn*p+bound*(nnn-1)))\n",
    "    for i in range(N):\n",
    "        m = np.mod(i, nnn)\n",
    "        n = int((i-m)/nnn)\n",
    "        m = m * p + bound * m\n",
    "        n = n * p + bound * n\n",
    "        atom = D[:, i].reshape((p, p))\n",
    "        if atom.min() < atom.max():\n",
    "            atom = (atom - atom.min()) / (atom.max() - atom.min())\n",
    "        img[m: m + p, n: n + p] = atom\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BptBSuNQ64ak"
   },
   "source": [
    "Define a function to perform the sparse coding using your favorite algorithm (IRLS, FISTA or ISTA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MDlsdgp68Ci"
   },
   "outputs": [],
   "source": [
    "def IRLS(s, D, lmbda, x0=None):\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EVoq64RP6-kk"
   },
   "source": [
    "Load the image and rescale it in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRItOr027BVK"
   },
   "outputs": [],
   "source": [
    "img = imread('BM3D_images/barbara.png') / 255\n",
    "imsz = img.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eS9awY-77EeL"
   },
   "source": [
    "Set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oii0m41f7F26"
   },
   "outputs": [],
   "source": [
    "# patch size\n",
    "p = 8\n",
    "\n",
    "# number of elements in the patchfrom skimage.io import imread\n",
    "M = p ** 2\n",
    "\n",
    "# number of columns in the dictionary\n",
    "N = 96\n",
    "\n",
    "# extract the random patches from the noisy image\n",
    "npatch = 1000\n",
    "\n",
    "# only few MOD iterations are needed for a good dictionary\n",
    "max_iter = 10\n",
    "\n",
    "lmbda = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwKu4JL87Je2"
   },
   "source": [
    "Extract $npatch$ random patches from the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OgXVqGNl7Ttq"
   },
   "outputs": [],
   "source": [
    "S = np.zeros((M, npatch))\n",
    "#S ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ynOk7uYr7cvU"
   },
   "source": [
    "Initialize the dictionary randomly and the normalize the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rrkaVUCO7fgt"
   },
   "outputs": [],
   "source": [
    "# D =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NZltkicV7iht"
   },
   "source": [
    "Initialize a matrix for the coefficients of all the patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzj2vAn77nwc"
   },
   "outputs": [],
   "source": [
    "# X ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pJx4qIsh7oSj"
   },
   "source": [
    "Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Z8XQNrG7qLQ"
   },
   "outputs": [],
   "source": [
    "for iter in range(max_iter):\n",
    "\n",
    "    # perform the sparse coding for all the patches in S\n",
    "    for n in range(npatch):\n",
    "        s = S[:, n]\n",
    "        # x =\n",
    "        X[:, n] = x\n",
    "\n",
    "    # MOD update\n",
    "    # D =\n",
    "\n",
    "    # normalize the column\n",
    "    # D =\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZGaziVS7rdn"
   },
   "source": [
    "Show the dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FqHV9pHR7saw"
   },
   "outputs": [],
   "source": [
    "img_dict = get_dictionary_img(D)\n",
    "plt.figure()\n",
    "plt.imshow(img_dict, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "luYMvFoa7wOp"
   },
   "source": [
    "Denoising via $\\ell^1$ sparse coding (use a dictionary learned by KSVD)\n",
    "------------------------------------\n",
    "Set the noise level and add the noise to the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6JBB5ylJ71HE"
   },
   "outputs": [],
   "source": [
    "sigma_noise = 20/255\n",
    "noisy_img = img + np.random.normal(size=imsz) * sigma_noise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y7HK4Qlr8Hqa"
   },
   "source": [
    "Compue the psnr of the noisy input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iTO-fkTj8FwJ"
   },
   "outputs": [],
   "source": [
    "# psnr_noisy =\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4k9TAEv8OqK"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax[0].imshow(img, cmap='gray')\n",
    "ax[0].set_title('Original image')\n",
    "\n",
    "ax[1].imshow(noisy_img, cmap='gray')\n",
    "ax[1].set_title(f'Noisy image, PSNR = {psnr_noisy:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gEUzAQJ8Qv0"
   },
   "source": [
    "Use the dictionary computed with the MOD or load a pretrained dictionary $D$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q1rO7pMs8ZHM"
   },
   "outputs": [],
   "source": [
    "D = loadmat(f'{rootfolder}/data/dict_nat_img.mat')['D']\n",
    "\n",
    "# show the dictionary\n",
    "D_img = get_dictionary_img(D)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(D_img, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ue9PsXb9Txk2"
   },
   "outputs": [],
   "source": [
    "# initialize the estimated image\n",
    "img_hat = np.zeros_like(img)\n",
    "\n",
    "# initialize the weight matrix\n",
    "weights = np.zeros_like(img)\n",
    "\n",
    "# set the threshold\n",
    "tau = 2.2\n",
    "lmbda = tau * sigma_noise\n",
    "\n",
    "# define the step (=p for non overlapping paches)\n",
    "STEP = 4 # STEP = 1 might be very time consuming, start with larger STEP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UhGFrleuTzyn"
   },
   "source": [
    "Operate patchwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iZV1qd-DT5vG"
   },
   "outputs": [],
   "source": [
    "for i in range(0, imsz[0] - p + 1, STEP):\n",
    "    for j in range(0, imsz[1] - p + 1, STEP):\n",
    "        # extrach the patch with the top left corner at pixel (ii, jj)\n",
    "        # s =\n",
    "\n",
    "        # store and subtract the mean\n",
    "\n",
    "        # perform the sparse coding of the patch s to compute the coefficients vector x\n",
    "        # x =\n",
    "\n",
    "        # perform the reconstruction\n",
    "        # s_hat =\n",
    "\n",
    "        w = 1\n",
    "\n",
    "        # add back the mean\n",
    "        # s_hat =\n",
    "\n",
    "        # put the denoised patch into the estimated image using uniform weights\n",
    "        # update img_hat\n",
    "\n",
    "        # store the weight of the current patch in the weight matrix\n",
    "        # update weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rSc72uk8T-AS"
   },
   "source": [
    "Normalize the estimated image with the computed weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9Jsy1iYT_fJ"
   },
   "outputs": [],
   "source": [
    "# img_hat ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S7ItjKLoIy1M"
   },
   "source": [
    "Compute the psnr of the estimated image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuwTIEL3I1Ki"
   },
   "outputs": [],
   "source": [
    "psnr_hat = 10*np.log10(1 / np.mean((img - img_hat) ** 2))\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(img_hat, cmap='gray')\n",
    "plt.title(f'Estimated Image,\\nPSNR = {psnr_hat:.2f}')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
