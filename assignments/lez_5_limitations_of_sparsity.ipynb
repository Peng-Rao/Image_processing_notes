{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 365,
     "status": "ok",
     "timestamp": 1741049613909,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "opwp5eU9E-8f"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.fftpack import idct\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7j9pcXTvFl_h"
   },
   "source": [
    "Variable initialization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1741049613916,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "u7PgrQa4Fkln"
   },
   "outputs": [],
   "source": [
    "N = 32  # signal dimension\n",
    "M = 32  # number of atoms in the span (for basis M = N)\n",
    "\n",
    "C = np.zeros(\n",
    "    (N, M)\n",
    ")  # matrix containing the standard basis (a kronecker delta in each column)\n",
    "D = np.zeros((N, M))  # matrix containing the DCT basis (a DCT function in each column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-NB1-MvmFsot"
   },
   "source": [
    "Generate the 1D-DCT basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 106
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "error",
     "timestamp": 1741049613923,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "Rey7kIlUF22r",
    "outputId": "244b6f30-edef-4a2e-9db7-28d119528071"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "    D[:, i] = idct(np.eye(N)[:, i], type=2, norm=\"ortho\")  # DCT basis\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.imshow(D)\n",
    "plt.title(\"DCT basis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cq78PWSDFw7G"
   },
   "source": [
    "# Sparsity w.r.t orthonormal dictionary D\n",
    "\n",
    "In this section you will perform denoising of a signal that is _sparse_ w.r.t. the orthornormal dictionary $D\\in\\mathbb{R}^{N\\times N}$, i.e., the 1D-DCT dictionary.\n",
    "\n",
    "At first, generate a vector $x_{orig}\\in\\mathbb{R}^N$ that is $L$-sparse, i.e. $\\|x_{orig}\\|_0 = L$. Use this coefficient vector $x_{orig}$, generate a noise-free signal $y\\in\\mathbb{R}^N$ as $y=Dx_{orig}$, and add some Gaussian noise to obtain $s = y + \\eta$.\n",
    "\n",
    "Perform the DCT denoising on the noisy signal $s$ to recover $\\hat y$. Use the Hard Thresholding operator that keeps only the largest $L$ coefficients and evaluate the denoising performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjPjQ3evRZM9"
   },
   "source": [
    "Set the sparsity level $L$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 79,
     "status": "aborted",
     "timestamp": 1741049614001,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "RWfXEyuaxAlj"
   },
   "outputs": [],
   "source": [
    "L = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kui72O2dw3xc"
   },
   "source": [
    "Randomly define the coefficients of a sparse representation $x$ (make sure the nonzero coefficients are sufficiently large)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 632,
     "status": "aborted",
     "timestamp": 1741049614004,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "PHuWhKkwFdIR"
   },
   "outputs": [],
   "source": [
    "x_orig = np.zeros(N)\n",
    "# Randomly select L positions for non-zero coefficients\n",
    "nonzero_indices = np.random.choice(N, L, replace=False)\n",
    "# Assign sufficiently large random values to these positions\n",
    "x_orig[nonzero_indices] = np.random.randn(L) * 100 + np.random.choice([-1, 1], L) * 3\n",
    "x_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yj3t4oWxwpOH"
   },
   "source": [
    "Synthetize the corresponding signal in the signal domain and add noise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "aborted",
     "timestamp": 1741049614006,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "yOPV-2k9wv7O"
   },
   "outputs": [],
   "source": [
    "y = idct(x_orig, norm=\"ortho\")\n",
    "\n",
    "s = y + np.random.normal(0, 1, N)  # add noise to the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KRBSmSG5GIPe"
   },
   "source": [
    "Plot the sparse signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 663,
     "status": "aborted",
     "timestamp": 1741049614035,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "m1NfJRxKGKFu"
   },
   "outputs": [],
   "source": [
    "LN_WDT = 2\n",
    "MRK_SZ = 10\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.plot(y, \"b-o\", linewidth=LN_WDT + 1)\n",
    "plt.plot(s, \"r--x\", linewidth=LN_WDT - 1)\n",
    "plt.title(f\"Sparse signal in DCT domain (L = {L:.0f})\")\n",
    "plt.legend([\"original (y)\", \"noisy (s)\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y4O1zq_JGPeL"
   },
   "source": [
    "### Implement the DCT denoising\n",
    "\n",
    "This is expected to be very effective on $s$!\n",
    "\n",
    "**Analysis**: compute the coefficients w.r.t. $D$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 665,
     "status": "aborted",
     "timestamp": 1741049614038,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "9OtzbfA_GRIA"
   },
   "outputs": [],
   "source": [
    "x = D.T @ s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDzCdJkvxazx"
   },
   "source": [
    "**Hard Thresholding**: keep only the $L$ largest coefficients (absolute value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 666,
     "status": "aborted",
     "timestamp": 1741049614039,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "_smviSBHxeMY"
   },
   "outputs": [],
   "source": [
    "x_hat = np.zeros_like(x)\n",
    "# Find indices of L largest coefficients by absolute value\n",
    "largest_indices = np.argsort(np.abs(x))[-L:]\n",
    "# Keep only these L largest coefficients\n",
    "x_hat[largest_indices] = x[largest_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o_0Wg_caxo6Y"
   },
   "source": [
    "**Synthesis**: invert the transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "aborted",
     "timestamp": 1741049614041,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "lTZ2OY_Pxrix"
   },
   "outputs": [],
   "source": [
    "s_hat = idct(x_hat, type=2, norm=\"ortho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1c_yWofxvoV"
   },
   "source": [
    "Plot the results:\n",
    "\n",
    "- are the denoising performance good?\n",
    "- are the original coefficients $x_{orig}$ recovered by $\\hat x$?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "aborted",
     "timestamp": 1741049614042,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "WpUm6mJ2xxxo"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].plot(y, \"b-o\", linewidth=LN_WDT + 1)\n",
    "ax[0].plot(s, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[0].plot(s_hat, \"m--o\", linewidth=LN_WDT)\n",
    "ax[0].set_title(f\"Sparse signal in DCT domain (L = {L:.0f})\")\n",
    "ax[0].legend([\"original (y)\", \"noisy (s)\", \"hard-thresholded estimate (shat)\"])\n",
    "\n",
    "\n",
    "ax[1].plot(x, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[1].stem(x_orig, linefmt=\"b-\", markerfmt=\"C0o\")\n",
    "ax[1].stem(x_hat, linefmt=\"m-.\", markerfmt=\"C1o\")\n",
    "ax[1].set_title(\"DCT Coefficients\")\n",
    "ax[1].legend(\n",
    "    [\n",
    "        \"coefficients of s (x)\",\n",
    "        \"coefficients of y (x_orig)\",\n",
    "        \"coefficients of s_hat (x_hat)\",\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yes, the denoising performance appears good. The hard-thresholded estimate effectively recovers the clean signal from noisy observations.\n",
    "- Yes, $\\hat{x}$ recovers the original coefficients $x\\_{\\text{orig}}$ well, especially the significant ones. The sparsity structure is preserved, which is the goal in DCT-based hard thresholding.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When the noise is large, HT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase noise level significantly\n",
    "noise_std = 5  # Much larger than the original noise (std=1)\n",
    "s_noisy = y + np.random.normal(0, noise_std, N)\n",
    "\n",
    "# Apply DCT analysis\n",
    "x_noisy = D.T @ s_noisy\n",
    "\n",
    "# Hard thresholding with same L\n",
    "x_hat_noisy = np.zeros_like(x_noisy)\n",
    "largest_indices_noisy = np.argsort(np.abs(x_noisy))[-L:]\n",
    "x_hat_noisy[largest_indices_noisy] = x_noisy[largest_indices_noisy]\n",
    "\n",
    "# Synthesis\n",
    "s_hat_noisy = idct(x_hat_noisy, type=2, norm=\"ortho\")\n",
    "\n",
    "# Plot comparison\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].plot(y, \"b-o\", linewidth=LN_WDT + 1)\n",
    "ax[0].plot(s_noisy, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[0].plot(s_hat_noisy, \"m--o\", linewidth=LN_WDT)\n",
    "ax[0].set_title(f\"High noise case (std={noise_std}, L={L})\")\n",
    "ax[0].legend([\"original (y)\", \"very noisy (s)\", \"hard-thresholded estimate\"])\n",
    "\n",
    "ax[1].plot(x_noisy, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[1].stem(x_orig, linefmt=\"b-\", markerfmt=\"C0o\")\n",
    "ax[1].stem(x_hat_noisy, linefmt=\"m-.\", markerfmt=\"C1o\")\n",
    "ax[1].set_title(\"DCT Coefficients - High Noise\")\n",
    "ax[1].legend([\"coefficients of noisy s\", \"original coefficients\", \"hard-thresholded\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the noise is large, HT might fail even at recovering the support of xo.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JXF-88C9yQF3"
   },
   "source": [
    "# Sparsity w.r.t redoundant dictionary\n",
    "\n",
    "In this section you will perform the same denoising as in the previous section with the only difference that the signal $s = y + \\eta$ that you will generate is sparse w.r.t. a redoundant dictionary $A=[C, D] \\in\\mathbb{R}^{M \\times N}$, where $C\\in\\mathbb{M\\times M}$ is the matrix representity the canonical basis, and $D\\in\\mathbb{M\\times M}$ is the usual 1D-DCT matrix. Therefore $A$ is a rectangular matrix, since $M < N$.\n",
    "\n",
    "To generate signals that are sparse w.r.t. $A=[C, D]$, at first generate a signal $y$ that is $L-1$ sparse w.r.t. $D$ as you have done in the previous section. Then, add a spike to $y$ that is sparse w.r.t. $A$. Bear in mind that the spike is to be considered a signal to be reconstructed, rather than noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aPAAAwcIVPNv"
   },
   "source": [
    "Generate the standard orthonormal basis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 668,
     "status": "aborted",
     "timestamp": 1741049614042,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "obxdA9V5yPnr"
   },
   "outputs": [],
   "source": [
    "for i in range(M):\n",
    "    C[:, i] = np.eye(N)[:, i]  # standard basis\n",
    "\n",
    "plt.figure(5)\n",
    "plt.imshow(C)\n",
    "plt.title(f\"Canonical basis dimension n = {M}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WkkR9rPyydtv"
   },
   "source": [
    "Generate a signal that is sparse w.r.t. D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 669,
     "status": "aborted",
     "timestamp": 1741049614043,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "cOiO5GVZyr6-"
   },
   "outputs": [],
   "source": [
    "x_orig = np.zeros(N)\n",
    "nonzero_indices = np.random.choice(N, L, replace=False)\n",
    "x_orig[nonzero_indices] = np.random.randn(L) * 100 + np.random.choice([-1, 1], L) * 3\n",
    "x_orig\n",
    "y = idct(x_orig, norm=\"ortho\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tWynseiYzHzy"
   },
   "source": [
    "Randomly place a spike in the first 20 samples of $y$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 731,
     "status": "aborted",
     "timestamp": 1741049614105,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "4MtcADV4zJaB"
   },
   "outputs": [],
   "source": [
    "# choose spike location\n",
    "spikeLocation = np.random.randint(0, N)\n",
    "# modify the signal intensity at spikeLocation\n",
    "# update y\n",
    "y[spikeLocation] = y[spikeLocation] + 1000  # add a spike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fzS-5-A0zOoZ"
   },
   "source": [
    "Add noise to the signal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 733,
     "status": "aborted",
     "timestamp": 1741049614108,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "vM1GUauPzQoB"
   },
   "outputs": [],
   "source": [
    "s = y + np.random.normal(0, 10, N)  # add noise to the signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WJH-ifZvzUOM"
   },
   "source": [
    "Perform hard thresholding by keeping the largest $L$ coefficients w.r.t. $D$ (not $A$!)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 734,
     "status": "aborted",
     "timestamp": 1741049614109,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "n7O-Wr1UzVlL"
   },
   "outputs": [],
   "source": [
    "# analysis: compute the coefficients w.r.t. D\n",
    "x = D.T @ s\n",
    "\n",
    "# keep only the L largest coefficients (absolute value)\n",
    "x_hat = np.zeros_like(x)\n",
    "x_hat[nonzero_indices] = x[nonzero_indices]\n",
    "\n",
    "# invert the transformation\n",
    "s_hat = D @ x_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgM1e9RUzrcJ"
   },
   "source": [
    "Plot the results and compare them to the one obtained in the previous section.\n",
    "\n",
    "Is the signal $s$ denoised properly?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 735,
     "status": "aborted",
     "timestamp": 1741049614110,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "Fn8Ptj0ZzvGn"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(12, 6))\n",
    "ax[0].plot(y, \"b-o\", linewidth=LN_WDT + 1)\n",
    "ax[0].plot(s, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[0].plot(s_hat, \"m--o\", linewidth=LN_WDT)\n",
    "ax[0].set_title(f\"Sparse signal w.r.t. A (L = {L:.0f})\")\n",
    "ax[0].legend([\"original (y)\", \"noisy (s)\", \"hard-thresholded estimate (shat)\"])\n",
    "\n",
    "\n",
    "ax[1].plot(x, \"r-x\", linewidth=LN_WDT - 1)\n",
    "ax[1].stem(x_orig, linefmt=\"b-\", markerfmt=\"C0o\")\n",
    "ax[1].stem(x_hat, linefmt=\"m-.\", markerfmt=\"C1o\")\n",
    "ax[1].set_title(\"DCT Coefficients\")\n",
    "ax[1].legend(\n",
    "    [\n",
    "        \"coefficients of s (x)\",\n",
    "        \"coefficients of y (x_orig)\",\n",
    "        \"coefficients of s_hat (x_hat)\",\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The signal s is not denoised properly.\n",
    "\n",
    "In the first figure, the noise level was low enough that the three original signal coefficients remained the three largest coefficients even after noise was added. Therefore, the hard-thresholding method correctly identified and isolated them, leading to a successful reconstruction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdLhGbFqkW5V"
   },
   "source": [
    "## Tichonov Regularization\n",
    "\n",
    "Compute the representation w.r.t. $A = [C, D]$ using Tichonov's regularization (try differente value for $\\lambda$)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 736,
     "status": "aborted",
     "timestamp": 1741049614112,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "X_Y7zSViHsm4"
   },
   "outputs": [],
   "source": [
    "lmbada = 1\n",
    "# Create the redundant dictionary A = [C, D]\n",
    "A = np.hstack([C, D])\n",
    "# Tikhonov regularization: x_hat = (A^T A + lambda*I)^(-1) A^T s\n",
    "x_hat_tic = np.linalg.inv(A.T @ A + lmbada * np.eye(A.shape[1])) @ A.T @ s\n",
    "s_hat_tic = A @ x_hat_tic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ENOHR2uH99W"
   },
   "source": [
    "Show the results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 738,
     "status": "aborted",
     "timestamp": 1741049614114,
     "user": {
      "displayName": "Giacomo",
      "userId": "00738787145430468476"
     },
     "user_tz": -60
    },
    "id": "DA4DZBl7IBGy"
   },
   "outputs": [],
   "source": [
    "LN_WDT = 2\n",
    "MRK_SZ = 10\n",
    "\n",
    "fix, ax = plt.subplots(1, 2, figsize=(16, 8))\n",
    "ax[0].plot(y, \"b--\", linewidth=LN_WDT + 1)\n",
    "ax[0].plot(s, \"r-\", linewidth=LN_WDT - 1)\n",
    "ax[0].plot(s_hat_tic, \"m-\", linewidth=LN_WDT)\n",
    "ax[0].set_title(f\"Sparse signal w.r.t. A (L = {L:.0f})\")\n",
    "ax[0].legend([\"original (y)\", \"noisy (s)\", \"Tichonov estimate (shat_tic)\"])\n",
    "\n",
    "ax[1].stem(x_hat_tic, linefmt=\"m-.\", markerfmt=\"C1o\")\n",
    "ax[1].set_title(\"Coefficients w.r.t. A\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While â„“2 regularization provides a computationally efficient solution, it does not promote sparsity.\n",
    "The solution ð’™ typically has all non-zero entries, which contradicts our goal of sparse representation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different values for lambda\n",
    "# Try different lambda values\n",
    "lambda_values = [0.01, 0.1, 1, 10, 100]\n",
    "\n",
    "# Create the redundant dictionary A = [C, D]\n",
    "A = np.hstack([C, D])\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, lmbda in enumerate(lambda_values):\n",
    "    # Tikhonov regularization: x_hat = (A^T A + lambda*I)^(-1) A^T s\n",
    "    x_hat_tic = np.linalg.inv(A.T @ A + lmbda * np.eye(A.shape[1])) @ A.T @ s\n",
    "    s_hat_tic = A @ x_hat_tic\n",
    "\n",
    "    # Plot results\n",
    "    axes[i].plot(y, \"b--\", linewidth=2, label=\"original (y)\")\n",
    "    axes[i].plot(s, \"r-\", linewidth=1, alpha=0.7, label=\"noisy (s)\")\n",
    "    axes[i].plot(s_hat_tic, \"m-\", linewidth=2, label=\"Tikhonov estimate\")\n",
    "    axes[i].set_title(f\"Î» = {lmbda}\")\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "    # Print reconstruction error\n",
    "    mse = np.mean((s_hat_tic - y) ** 2)\n",
    "    print(f\"Î» = {lmbda:>6}: MSE = {mse:.4f}\")\n",
    "\n",
    "# Remove the last empty subplot\n",
    "axes[-1].axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Image_processing_notes",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
