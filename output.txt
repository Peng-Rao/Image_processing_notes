Okay, today we go more in details into the image problem which is like our key problem we want to solve to better understand the use of these models. This is one of the simplest way the noise is, it's one of the simplest way you have to assess whether, to quantitatively assess whether an image prior is effective or not, because it's one of the simplest problem where you need a prior. So today we introduce another fundamental concept, fundamental ingredient which is not only related to our course but it's kind of more general value, which is the fact that when you are addressing a problem, you need to provide a formal description of the problem. In this course when you want to design a solution yourself, what is mandatory is to know, is to have a clear formulation of the problem you want to solve, otherwise it's not possible to design your own problem. So the first thing you need to do when you want to solve a problem is to define a problem formulation. This is what a second meeting with my students, definitely easy students, it's about problem formulation. So let's write down the problem you need to solve in your thesis. If you can't clearly formulate your problem, for sure you can't solve your problem being aware of what you are doing. And image denoising is a very simple and delicate form of formulation. So today we start from there. In image denoising, denoising in general you can say, what you observe is a noisy observation, z, which can be either a vector, an image, a portion of an image. And then since we are facing the denoising, the images, then we denote by x the vector describing the coordinates. So z(x) is the noisy observation of the pixel of the coordinate x. So x lives on a grid in the orbital x. The set of pixel locations, so that's good. So what you observe, it's a noisy observation where by noisy means that there exists an underlying signal, which we call y, which is the ideal image. It would acquire, if you have a perfect sense, the noisy free image. Plus what you have, it's a noisy component, noisy realization. So this is telling you already a lot. You need to add like a few things. Now I need to tell you about the noise component. But this is already telling you that you assume that the noise is additive. This can be used to design your algorithm. Okay, then is this model good? The real answer is not, but most often, so the noise is a bit more sophisticated than this. But indeed, most of the denoising algorithms are actually designed for this model, for this type of observation model, because you end up to this type of observation by transforming the image. It's not a good model if you want to denoise a picture by your phone. This is not a denoising algorithm implemented here inside. This is not an observation model that is used to design the zygotes in your phone, but all the zygotes for the noisy algorithm are meant for this model. Then there is something in between the bridges, the real observation to this. This is also called, now we say that eta is Gaussian noise, and also this assumption is also the additive Y Gaussian noise, which doesn't sound nice as an acronym, but additive Y Gaussian. Okay, so that's good. So noise observation in each pixel, I need to tell you a bit more about the observation. In each pixel what I observe, it's the ideal image, okay, plus some noise component, which is actually, are you all familiar with random variables, like basic notions of statistics, right? Am I right? It's a correct assumption. So this is like a stochastic component, completely random like atomic dice, and this is characterized by eta, which is a random variable, following a certain distribution. So this means that this is a Gaussian distribution, at least sigma. This is like, in each pixel, it's like throwing a dice, both output is actually following this distribution. If it was a normal dice, that would be like, the distribution would be 1, 2, 3, 4, 5, 6, right? A uniform discrete probability, you cannot get 3.5, right? And the probability is that the dice is not fake, it's equal, okay? So that's a uniform discrete noise. Typically, you assume Gaussian noise, okay? And this is also saying that the noise realization you have in one pixel is independent from the noise realization you have in the adjacent pixel. And this, we say this by saying that the eta is iid, independent and identically distributed. So in each pixel, you draw your dice independently, giving you a Gaussian number separately from the others. This is extremely good because when the noise is correlated, so if the noise is like this, any form of correlation in the image is related to the content of the image itself, any form of dependency between adjacent pixels. When the noise starts to be correlated, then the dependencies among pixels can be divided through the noise, or today you should. And you need to cope with that, okay? But I'm not touching this now. Because, again, then you find out a way to use the standard accuracy design for this. And today, when there is this problem, it's going to be very simple, very similar to the DCT diagram we have seen like last week on ECG signals, same problem as JPEG denoising, JPEG compression, but we will add a bit more ingredients to make denoising more effective. Okay? And this is already some algorithm you can use in practice, up to some modeling. Okay? So that's good. Any questions? Sure? Everything clear? Please stay clear. It's too simple, to feel offended like, no, don't feel offended. So this image formation model, observation model, called whatever you want, is telling us some prior on the image. Okay? So let's get back to the prior. Now, if this is the image space, like you have only two values for an image, of course, for a patch 8x8, you have 64 values. So this is R64, whatever. In my case, only two. When you observe a point, when you observe a patch or an image, I'm just taking a point in the space, right? Is this parallel clear to everyone? So what is this assumption saying? It's actually that, so what you really want, sorry, in denoising, I just forgot to say the most important thing. What you want to do, the goal, so this is the inputs. Now I tell you the answer to the goal, what I want to get. The goal is to estimate y hat that is close to y. We have an estimate of the original image that is close to y. Okay? Now, when I observe a point, when I observe a patch, that's corrupted by noise, right? Can I tell you, can I tell where y is? So if I observe this patch, can I tell where the original image is? Is it more likely that the original image is here or is it here? Which of the two? Y1 or Y2? Y1. Why? Because we assume Gaussian noise. Because we assume Gaussian noise, okay? So basically, it's like that, we can say that y, right, is equal to z plus eta, minus eta, or plus or minus, it's noise, okay? So it's like that y is likely to be around z. I've drawn circles because the noise is the same in each pixel, in each component. So it's really circular shape because the variance is the same along each pixel. In each pixel, there's no correlation. If there were correlation, it could have had, okay? That's a priorl, not on the image, but a priorl of noise. And that's equally important when you want to design a Z-angle algorithm. You can't remove noise if you don't know the distribution of noise, okay? That's not my priorl of the noise. Now, if I were only with this prior, what would be the best estimate? I can tell. So what would be, if this is, this is what you observe. This is the distribution of the noise, so where Y should be. So this is good because you can say that this is more likely than this. You follow me? But what would you choose if you only have this assumption? What would you choose as Y-art? Z, because this is like the peak of the Gaussian, the most likely realization. So that's, I wouldn't say it's completely useless as a prior, but that's simply not enough. Because you would say the most likely realization, if I have a noise that is centered in zero, the most likely realization is zero, centered with a peak in zero, like a Gaussian in zero. So if you need to choose, like, randomly you would say the noise, actually there's no noise. The image is noise-free. I would return as Y exactly Z because the most likely realization is the noise equals zero. So that's not enough as a prior to perform the noise. Everyone on the same page? Now, what do we need in order to design a noisy Gaussian? A prioron on D? On the noise, it's already there. That's the prioron noise. It is telling you that what you observe, Z is actually corrupted by, is Y the noisy free image, corrupted by noise. So that's the prioron noise. That's analytical. It's a Gaussian distribution. I mean, there are three terms important, guys. One is the noisy observation. The other is noise, and we already used the prioron to do these two. So we need a prioron on the original image, on Y. It's okay? Now, we are not going to have analytical priors on Y. You see, we have an analytical prior. We can draw these circles, okay? We are not going to have these for Y because that wouldn't be a fact, okay? But in principle, it's like if you had a prior on your image, that's your prior on Y. You follow me? Okay? And now what you want to do is to trade off between the prioron the image, sorry, the prioron observation, the prioron noise, and the prioron the image. You are not going to take this point as an estimate. Most probably, you are going to take a point along this line, which trades off a bit on the prioron noise, which is called the delta fidelity term, say, how close you are to your observation, and the prioron being, which is how likely your estimate for Y is to belong to an image space, the space of images. So that's the philosophy of the noise. Do you follow me? Any question? Don't be shy. Ask questions. Okay? Now we develop some priors, and we are not going to put this, like, analytically, because if we take an analytical prior such that we can draw the -- that would be very cool in describing the initial images. Okay? Good. So now we will take, to just start, as a reference image, a very simple image, like a normally simple image, which is checkerboard. And you can draw checkerboards in -- Commons. Matlab, there used to be -- so there is also in Python, which we know is derived from Matlab. You can find the same common rules in Python, I assume. So let's take this image, and now let's think of -- so this is the ideal image Y, right? Then it's corrupted by noise, so it's not going to be, like, binary image in there. So zero, one. Zero for the black, one for the Y. It's okay? Is everything clear? What do you mean by this natural image? This simple image? Now, what would be a good prior? For -- I'm sorry. We are not designing prior for the entire image. Simply, it doesn't work. It's too hard, too complicated. So we are drawing -- we are designing priors for small patches. As for JPEG, you have seen, like, last week. So we take a patch. So now we can also take, like, a one-dimensional illustration, okay? Which is simple to do, you know? Okay? So it's like I'm taking just this line of this patch. So what you have here -- let me remove the distributions -- is that on this patch, you have the true image, which is flat, okay? So if you take X and Y, it will be a plane, like parallel to X, Y -- say, photograph to the Z axis, a constant video. But then you have some noise around, okay? You follow me? So this is Z. So the points are Z. The dashed line is Y. Now I'm asking you, what would be a good prior to estimate Y? What would be a good assumption to design your algorithm for this specific case where images are constant? Like that the signal is constant, right? So you can say, my prior is that on a small patch, the signal is constant. I'm not saying it's constant the entire image, otherwise I would have only flat images. That's not a good prior. But don't lock patches on small neighborhoods. I can assume that. Which is kind of good for this very simple checkerboard image we are starting from in this lecture, okay? So now, if your prior is that the image is constant, what would you do to estimate Y? Here. Please. You will compute the mean, the average, right? So you will take all the noise -- of course you don't have this dashed line. This is the ideal image, right? So you will take all the noise -- I know this is extremely simple, okay? But this is just to tell you how to use an assumption. My image is locally constant. Okay? That means that you can take all the samples in the patch. So the patch is m-dimensional. Do you remember? And what you do is you compute the mean of Z of X I, right? Must be good. So let's see what happens. Now, this is simply one over m, so the sum over the patch, let's just say I, of Y, but Y is constant on my patch. So it should be Y of X I, but Y is constant. Y of X I plus eta of X I, right? Now I told you this is constant. That's a constant, K. That's really a constant. I mean, when I'm summing up the Z, I'm summing up the values of Y in it. Okay? So this is equal to K plus the sum over I of eta of X I. Simple. Simple calculus, okay? And what happens is that, so as you can imagine, now this is Y hat. This is like a random variable as well. So Z is a deterministic component plus some noise, which is a random variable. So this has a distribution, and the estimate as well. So let's look at the mean, the expectation of Y hat. Now, the expectation of Y hat is equal to K, because this is a bit of statistics, guys. The expectation is, say, if you take the expectation of this term, it's expectation of this plus the expectation of this, expectation of K, it's constant, sorry, it's K, plus the expectation of the sum of Y X I, okay? This is like noise. This is noise. This is sum of noise. So basically this means that you have K in your estimate, okay? You see? Plus some noise, which is the sum of all the noise. Sorry, here I forgot, it's one over N. There is one over N. Otherwise, it wouldn't be convenient, okay? Now, the expectation of this is zero, because the noise has expectation, which is zero, okay? So this is telling you that your estimate is pointing at the right signal, okay? So this is called also an unbiased estimator, because the expectation is equal to the signal. But this is good, like, you have, if you compute the automations and the signal is constant, what you get, what your estimator is pointing at is that it's noisy for your signal. That's the first property we would like to have. It's okay? Now, what about the variance? This is, you need to call, you need to leave with that, okay? What about the variance of this guy? One over M, the sum of K plus eta xi. Now, this is simple, because this is one over M squared. The variance, when you take this, you bring out of the variance, you write it to the square. This is the basic properties, statistics, and I think it's the only statistical notion you need to know for this course. So don't worry, it's not going to be like calculating statistical. Jeffery, it's going to be a real expectation of variance. That's also a good way of becoming familiar with this, for understanding how this works in practice in this signal. So that's good. So this is going to be the variance of K plus the sum over eta i, okay? Now, having a constant in the variance, it's not changing anything, okay? So this is like one over M squared times the variance of the sum of eta i, of eta xi. Okay, good? Do you follow, guys? Please tell me. Okay, any questions? You're suspicious. It's okay? It's too simple. Now, what about the variance of this guy, then? You're summing independent random variables. When you're summing uncorrelated random variables, it's independent in our case. This is equal to the sum of the variances. So this is one over M squared times M times sigma. Okay, am I right? Mathematicians, where are mathematicians? Have they already disappeared? We are mathematicians, right? Sigma squared, of course. We are mathematicians, right? Yes, okay. The only mathematicians, can I use the singular? Are there any other mathematicians left? We are the only. At the second. Okay, two. Stay closer, okay? Never surrender. It's okay? So this means the variance is one over M sigma squared. So what you get in the output y hat is equal to, say, k, which in our case is actually the original signal, y, plus, say, some other noise. It's still a Gaussian. The sum of independent Gaussian is still a Gaussian. Where eta squared follows a distribution that is zero, sigma squared divided by M. So basically, you have reduced the variance. This means that what you get, your estimate, will be a much less noisy image, because you are dividing by M, divided by 64. In our case, where M is 8 by 8, it's okay? So basically, what you will get, if you do this for each pixel here, your estimate will be fluctuating around k, with much less noise than the noise we have in each pixel. It's okay? So far, so good? This is also called, this is basically, if this is a good project, so this is, you just spend some time considering this, if this is a good project, you find that the images are flat, this is the best you can do. The statistician says this is blue, best linear unbiased estimator. Am I right? Not the mathematicians' friends? Best you can do. Because it's unbiased, unbiased means that, except for noise, you are pointing at the real signal, okay? And it has the lowest variance, excellent. Now, unfortunately, if I take a patch, which is here, right, then I take again, I draw just one row of my patch. What I have is that the signal is like this, then there is a jump, right? So my signal is like this, okay? Now, if I'm denoising just, okay, let's say we are taking a large region, right? So as long as I'm here, my denoising algorithm will be excellent. My denoising algorithm is based on computing local averages, okay? But then, as you can expect, when you are here and you compute a local average, like an average of these, what you get is that your estimate goes down and gets like this, okay? So here, you are unbiased. Here it works perfectly. But here, you are very far apart from your original image. Here, you are introducing a bias. This is false, because the image is not constant. So you see why I did all these calculations, just because of that. By the end of the course, we know we are not using these types of problems, but by the end of the course, you will be able to implement ideals that, for each piece, defines like a patch where to compute an average, such that if you are here, you will take this neighborhood. If you are here, you will take this neighborhood. This is adaptive filtering, and we will see that by the end of the course. You remember, last lecture, I was showing this animation of the cameraman image where there was this -- yeah. This is designed based on the trade-off between bias, which is the way you fail here, and bias, which is the way you fail here. Bias, bias, trade-off. We will get -- we see that. It's okay? So far, so good? True? Now, so this is not a good priority for images, but this is the priority we enforce when you just perform smoothing. You just perform local smoothing, like when you do the running averages, the moving averages over your signal. So, when you say, "I have this signal, which is a bit noisy," right, then I compute the running average, the moving average. That's exactly the underlying assumption you have in mind. The signal is corrupted by some noise. I suppress noise by averaging over a neighborhood. This is good as long as the signal is constant. This is not good when the signal is not. And we will see also, by the end of the course, that we can have more, like, better feet, like, polynomial feet, say, not a constant. Higher-rooted polynomials. And, by the way, this is when you repeat this operation, like, computing the average over a neighborhood in each pixel, this is if you wanted to compute the convolution. It's not just convolution, okay? So, basically, the convolution operator is actually what we can analyze, like, z convolved by h in a pixel. That's equal to -- oh, I'm writing down the 1D case, then you sort it out for the 2D. It's like mixing together all the pixels around x. So for each location, X, you take a neighborhood, capital U, and this is a way to say I'm summing up all the values with a coefficient H. And what we did is actually the convolution against the coefficients of the system, which is one over n, one over n, one over n, one over n, one over n. So when you take your image, no noisy image, and you say, okay, let's compute a moving average, and let's say, let's make a Gaussian smoothie go, let's make a, let's compute a moving average, what you are doing is exactly easy. Then try this in Python, you see what happens, the image will lose details, because you are replacing the transformation by the average neighborhood, which is like, my prior is that the image is constant. It's a good prior. No, you see from the resulting image. Okay. The convolution has the use the minus sign here in this course because this is the way it is defined. In deep neural networks, there is no minus sign, because you are learning H. So there is no point of having like this minus sign, because this equivalent, you just thought that this problem is equivalent to like this. Just change you. And this means that if the filter is these, rather than using a, it is equivalent that you have your signal, you overlap the filter to your signal, you perform pointwise multiplication, you sum everything together, the convolution. In convolution we preliminary flip the filter, because there is a minus sign which means, like this, it's a 2D, you need to flip like left to right, upside down. But if the signal is flat, if the filter is like constant, there's nothing to happen. But when the filter is non-same matrix, this makes a difference. So when you design your filter, you need to take this into consideration, that the convolution is defined as the minus sign. Okay. That's a minor technicality, but remember this. Okay. Good. So, basically, we will get back to the noising by convolution at the end of the course, because it has a nice interpretation when we can leverage like higher order fit, not just a constant, and when we can define adaptively the neighborhood where to perform filter. So that's very nice, the noising algorithm. Okay. But now, of course, here we use, for the first part of the course, for the main course, we will use as a prior sparsity. Okay. And we know that sparsity is a great problem because, I mean, the picture you shoot in your phone are saved in JPEG form, right? You have seen with Eduardo last week that JPEG is a powerful compression algorithm. You know that it's a powerful compression algorithm because it's implemented anywhere. And it is based on encoding only the large coefficients in the DCT domain. It's okay. Guys, everyone on the same page? So we know that sparsity is the same. Assuming that the image is sparse with respect to DCT basis, it's an effective prior, which is used for compression that we can use also for the noise. So this stuff, which we hold here, it won't be, it won't say you have an analytical shape, some stuff you can draw, but it will be that my image has a sparse representation with respect to the DCT basis. Okay. So finally, one question. Why sparsity is good for compression? I don't get why it's good as a prior to assume statistically that your noise will show up in the small components. Okay, good question. So, actually, it's wrong what they say that it's a good prior for compression, say it's a good prior for the image that we use for compression. So, natural images, which are noise free, we know that this, so you can think of z remove the x. So just think of enable a patch. You can look at this expression like that say not not pixel wise, and we know that this is a vector. And we have been like, and we know that this vector that needs a sparse representation with respect to the DCT basis, or that we can nicely approximate this guy by a sparse approximate by a sparse representation. Okay. I mean, we can always do this, we can always assume a prior. But we know that this prior is effective in the noise, because indeed, why is a sparse representation, because otherwise JPEG wouldn't be based on that. Now, we know that why is sparse with respect to DCT basis. We use that for compression, which means that we take our patch, transforming this domain, perform the shoulder and we just keep the nonzero coefficient encoded. Now the idea is to use this prior for denoising as well. Okay, so the prior is not related to denoising, the prior is related to the image itself. It's okay, did I answer your question. Any other question, maybe one question that goes for another. I think clear for everyone or completely. Okay. Good. So now, now what we will do today is to use this prior say the sparsity with respect to the DCT domain. And you see that it's way better than assuming that the image is flat. So maybe this is not included in the assignment but please compare what you, because I forgot to modify yesterday. But please, and I also forgot to upload the slides I will upload later. Please compare the denoising we can get now. With the denoising we can get by this assumption that the image is constant, which is simply obtained by convolution against a filter that is constant. Which is like computing local advantages. It's okay. Good. Now, so now we want to use sparsity. Sparsity as a prior. The rest of the lecture, which is, it's very related on all of this six stuff. It's very related to how to leverage this prior denoising pipeline. Okay, and we have D, which is the DCT basis, the two DCT basis. We have been plotting this right in the past, the DCT matrix for two D, for patches in the last assignment. Now, the idea is that you given your image, and again, let me take the checkerboard image, whatever image in a, don't take the checkerboard, because the checkerboard is boring. We can take any image. Let's take, this is the image with some content, I don't know. So this is a patch. Okay. So we call this patch, now we call it Z, before it used to be called S. I can call it S, which is equal to Y plus eta. And this is like in vectors. Okay, so this is the unfolded patch. Okay, S belongs to RM, where M is 64, eight by eight. So you take your patch, which is this one, which is noisy. And you unfold it in a vector. Okay. So this is your observation S. And we say this is equal to the noise if we patch Y, which you want to estimate, plus some noise realization. And the noise is a vector of noisy values, where eta is distributed again with a Gaussian. Okay. Now we drop each patch, and then what we do is the first step is the analysis, right? So we compute X, which is equal to D transpose S. You remember the noisy pipeline. So here we go in the domain of coefficients, where if we were starting from Y, we knew that X would be sparse. Okay. But, I mean, unfortunately, X is not going to be sparse because of noise, because we have also seen this in the last lecture, which is ECG signals. But you can see also, if you do like, this is D transpose Y plus eta, so X is equal to D transpose Y plus D transpose eta. And even if this is sparse, this is not. Okay. This is not sparse. This is dense. However, we know that sparse or not, what we can do, like, it's transpose sparse. Right? And doing threshold. So the second step is to enforce your prime. So we say that X hat is now equal to gamma X. Gamma is the threshold, is the threshold in operator. So, like, you take your vector, so we add like S, which is this vector, which we know it's equal to D. This is m by n times X. This is dense. Then we do thresholding, and we just keep a few coefficients. Okay. Remember that. Now, thresholding is defined pixel-wise. Okay. I mean, I can't remember how you, I don't know how you implemented that if you were taking only the largest, or if you were setting a threshold equal to the value of the L largest coefficient or whatever. Let's take, if you got what you do, you take the largest. And so basically, what you need to do is to say, you say that X i in the i-th component is equal to zero if X i in absolute value is smaller than gamma. And X i if X i is larger than gamma. Okay, so that's pixel-wise. The first point would be how to set gamma. Later. I'll tell you later in a second when I'm done with the outcome. Now I continue here below. I need to remove all these calculations on the bias and the. The third step is basically to reconstruct your signal, right? Remember, so we get back to, so it's like X, sorry, S, X, X-th, so this is thresholding. This is an analysis. And then there is the synthesis. Or you say that S-half is equal to T times X. And of course, the two won't be equal. You don't want the two to be equal because this is noisy, right? So you want this to be different. But you hope this is similar to Y in the noisy framework. The noisy free image, patch, the noisy free patch. Question? Please. Is it correct to say that the value with the ECT is the fact that most of the information of the image comes from the low frequency? Okay, excellent question. The question is, is it correct to say that if the leverage in this sparsity with spectral density is like assuming that most of the information in the patch, in the entire image, but basically locally on the patch, comes from low frequencies? Now, this is like very, very motivated question because let's get back to the ECG signals, which we were drawing. I can't draw easily, right? So the word is ECG signal. Okay, do you remember? And then I was drawing the coefficients. Okay, and the coefficient indeed. So this is S. Now, we were drawing X equal to the representation of S. It was like this. Then we're going to zero. You remember, there was this illustration of, you should have, so that's why I say it's important to practice. Okay, and indeed, what we are saying, it's like how we keep the largest coefficients. And in this case, the largest coefficients were these. So it's like the largest coefficients in X were the first ones. Then in this case, that's equivalent. It is always inconsistent keeping the largest coefficients. Sorry, keeping the low frequency coefficients. Okay, but this is not what we are leveraging because if my signal has a large coefficient here, which are like here, I will keep them and maybe I will lose some of these. Why, if you keep only the largest coefficients, you wouldn't. Now, keeping only the largest coefficients, it's like computing a convolution by a specific filter. So those guys doing filter design can tell you which filter you should take. How is the filter age for the convolution done in order to keep only the largest coefficients? This is not an adaptive filtering because it's like you use always the same kernel, the same Gaussian filter, the same filter of Gaussian, same filter through the entire image. In our case, we say how we compute the analysis and we compute the representation, and there in the representation I will enforce some prior, which is that I will keep only few coefficients. So depending on the value these have, I will keep fewer or less coefficients. My filtering is adaptive because it operates differently on each patch. And I will get back on this, say, in discussing this parallel between what is like keeping the largest coefficient, keeping, enforcing sparsity or keeping only the low frequency coefficients. If you keep only the low frequency coefficients, you are surrendering in losing all the high frequency content like the patches, like the edges. I will show you a very good denoising result on the tracker board. But, I mean, we can handle the edges. If you do like keep only the low frequency, you will surrender. So it's a more powerful problem. Indeed, the beginning, only denoising was based on the beginning. Then you get to the sparsity, which is a bit of different mathematics behind. So now it's overlapping. And for some signals, perhaps they are like always the same because you can't draw the ECG signal by the low frequency. But in fact, it's there. And we will see that we can get into sparsity in a much more sophisticated domains where it is more effective. Thanks for the question. Any other questions or comments? So, Professor Wood, did you get also this answer, this point? Okay. So, the synthesis would be, sorry, you take the threshold, the vector, and you reconstruct the image by multiplication against D. Okay. Super simple. And, I mean, this operation is repeated for all the patches. So basically, what you will do, you take, like you take all your images on a tile, you divide your images in tiles. And for each tile, you undergo this process. Okay. Now, in order to make this algorithm effective, you need to set gamma. I mean, you need to set the threshold, right? So, but the threshold, typically, a good rule of thumb to set gamma is given by some statistician, like Dave Donald from Stanford, which they are based on some analytical derivation, some sparsity assumption. I think it's from wavelength domain, not for VCT, but as a rule of thumb, a good way of setting the coefficient, such a threshold, is this one. Now, you say, what a nasty formula. This is a formula which makes sense from some, which is the right one to some assumption. So, that's sigma, which is a standard deviation of the noise. Okay. And this actually moves to a different problem, how to estimate the standard deviation of the noise. Now, we solve also that problem, don't worry. Okay. And this is the square root of two logarithm of n, where n is the dimension of x. Now, you say, but you call this m. This is true, because n, because x and s has the same dimension, right? This is just for the first two lectures of the course, three lectures of the course. Then we will move to different settings. But the threshold is good, it's called universal threshold, it has to be, it's universal, okay? So, this is n, which is the dimension, the dimension of x, of your representation. Okay. And basically, if you take 64, q the logarithm of 64, it's incredibly close to three. So, gamma is almost three sigma, the three sigma root. Okay. At least it's the right one of some statistics. So, this is the universal threshold from down. But, in order to use this threshold, you need to know, guys, active participation. If you look at this formula, there are two log is log, and there is n and there is sigma. So, now I repeat the question. In order to use this formula, you need to know sigma, okay? And we know, because it's the dimension of the vector, right? Sigma is the bias of the noise, and the standard deviation of the noise, which is, okay, in some cases you can characterize your sense, and you can know how it works. But it's surprisingly good, right? It's surprising that you can get really good estimates of the standard deviation of eta, even from a single image. Okay. And so, the issue is how to estimate sigma, and how we take this portion of the one to estimate sigma. Basically, the assumption is very, the technique is extremely simple. So, this is, again, your observation model. Okay. Let me grab the notes. And now, of course, if you estimate the standard deviation of z, you won't get a good estimate of sigma, because the image has a lot of variations, and you will get the estimation, the variance of the image itself. But if you have, like, a checkerboard image, if you take the variance or the standard deviation of the entire image, it's more of the variance due to the image, rather than to the noise, because you have black and white pixels together, right? So, a simple trick used in image processing is to, it can be seen again as assuming a prior, a very coarse prior. Like, the two adjacent pixels have the same value, which we know is not a good prior for denoising, but it's a good enough prior for estimating the standard deviation of the noise. So, now, you, for each pixel, you subtract, you complete a difference between a pixel and a neighboring one. The adjacent one. And you do this for the entire image. And now, if you do this over this image, what you will get here, in this region, basically, you will have, like, noise minus noise, okay? Let's go back. So, if you take z of xi minus z of xi plus one, sorry, this is there. Well, if the image is constant, this is, like, eta of xi minus eta of xi plus one, which is not the adjacent pixel. And now, this is not zero, because the noise is independent realization, so this is, like, twice the noise. So, this is, like, two times the noise, which means that this guy is distributed as zero to sigma squared, correct? So, here, you perfectly have noise realization with twice the noise, okay? When the image is not flat, like, here, of course, you have a spike, because you have the difference between black plus noise and white plus noise. So, these guys give a large value, these guys, they don't, because I've just computed the difference with the right fix, okay? That's okay. But now, if the distribution of noise, so this is the distribution of eta, was like this, now the distribution of this guy, the difference between two adjacent pixels, so the distribution of this guy, I don't know how you want to call it, let's call it d, d of xi, which pose you for the derivative, the d derivatives are computed by differences, the horizontal derivatives are computed like this, the vertical derivatives are equal to one. Okay, that can be, so the distribution of d is going to be like this, okay? So, now you can say, perfect, I take differences between an image and the adjacent pixel, and then I get this distribution, it could be the standard deviation. It's okay. This is good, as long as the image is flat. Naturally, it is not even very good because then there are these guys, so you understand why there are these very large pixels here, so these very large pixels will give you a spike over here, over here in the distribution. This can make the estimates of the standard deviation depart from the real noise. But this is, now it's a simpler problem than image denoising, because what you do, rather than computing the standard deviation of d, which is the difference between an image and the adjacent pixel, rather than computing the standard deviation of d, which will give you two sigma, rather than the sample standard deviation, you use a robust estimator. The robust estimators are statistics, but they don't answer the other statistical notions of statistics. But they just tell you what is the robust standard deviation. So if you take the sample standard deviation of this, it will be much larger because of these two guys' peaks. And the more the image departs from the checker mode, so the more you get close to a natural image, the more he retains you with them, when you're computing differences between an image and the neighboring pixel. But now, indeed, the standard deviation is like to move the spread around the peak. So if you can take an estimator that is not affected by details for the standard deviation, then the estimate of the standard deviation is very good. And the robust estimator for the standard deviation is the map median of absolute deviation. That's surprisingly robust, there's an estimate. And the median of absolute deviation is like, as the word says, the median of absolute deviation of a population is the median of the absolute deviation of the median. So effects from the median of X. So the idea is first, compute differences. D is equal to Z convolved with -1, 1. Image differences. The convolution is like you compute differences between each pixel and the adjacent one. You can write it as a convolution against the field. Okay? Otherwise, you can take an image, you can shift off one column right, it could be the difference among these guys. It's okay? Or you can write the problem. First step is compute the image differences. And the second step, you compute the sigma is equal to the median of absolute deviation of D. That's like, as you write STD, you can write MED. You get the robust estimator. But as our mathematician friends will remind me, this is not exactly an estimate of the standard deviation, then the median is defined by these. But the estimator of the standard deviation needs to be divided by a magic number, which perhaps you have encountered somewhere else. Which is zero, seven, zero, six, seven, six, five. This is a normalizing, we didn't know. They are multiplied by one. Okay, it's a nasty number, which comes from the Gaussian, some area below the Gaussian. Just take this. Okay, this is the magic divided by zero, seven, six, five, which is an estimate of sigma. A good estimate of sigma is given by this. And so you take sigma and just check your function, whether it's already computing this, whether it's already normalizing by this. So if you're using a function, just make sure whether it is dividing or not. Okay, if you do implement this like this way, which is one row, one line function, you need to divide. Otherwise, if you're using like some library, just double check. And then it has to be divided by the square root of two also. Because the variance is to sigma, and the standard deviation is square root of two sigma. I forgot, but you didn't correct me in the notation, so you need to help me out, okay? So it has to be divided by the square root. That's the effective way of estimating the standard deviation of the noise. And it's surprisingly good, even in a natural image, which is far from being flat. Because you get rid of the image content, or at least you get to something that, in many cases, from quite a few pixels, it's only noise. And then you can estimate all the standard deviation over those subs. So that's extremely good estimate of the noise standard deviation. Okay. Good. So we are putting in place, any question? No? We are putting in place like a region-effective denoising pipeline, because that's the denoising pipeline. Dark. So you take a patch over a grid. You do the analysis. You have forced velocity. We know how to set gamma. Because we take three or two square root, the logarithm of n. This formula is more general. I mean, if you take, like, larger patches or smaller patches, you'll get the estimate of structure, which works well in any case. If you have a one-dimensional signal also, and it's smaller, okay, it's eight. Then, and you use this gamma, the standard deviation of the noise, which is either given, either you can compute waveform. It's okay. So this denoising algorithm should be much better than rooting. Still, it's suffer of a big problem, which is -- so this is the PCT denoising. It's suffer of a big problem that makes the farmers of the algorithm very poor. Say, be visually. It's the part that you're processing each patch separately. Okay, sorry, I forgot one important point. Here, one important detail. When you enforce sparsity, you don't want to change the mean of the image. Because otherwise, if you do thresholding on the average of the patch, you will have patches that are of different average intensity. So this is for i larger than, larger or equal than 1. So when you do this, typically you compute x, you store. So either you do thresholding only on all the coefficients, but the first. So this is not to be modified. Sorry, the first coefficient is the average. Because in the CT basis, the first coefficient is a constant. So this is not to be modified. So thresholding is to be applied on all the other coefficients, but the first. It's okay. Remember this, because otherwise, you don't want to modify the average. In practice, you never modify the average of the image, the average of the patch. Still, even if you preserve the average of the patch, what you typically have is that between one patch and the other, there are some artifacts. Okay. And I can show you what happens in case of the checker of the image. So remember that never touch the coefficients. So this is for i equals 0, the first coefficient that is what happens. Why? Why this is not sharing? You have nice slides prepared, yes, just for you. Why these guys not sharing? Let's make it last up 10. Oh. No. Let's see whether. Oh, here we are. Perfect. So this is the. So what I was saying is this is the noisy checker board, right? What this checker board was designed for like each type of the checker board is 16 by 16. And you are doing the noisy by patches that are 8 by 8. So this is a very corner case, but just make these problems area. Okay. Now, if you do the noisy using all the styles like that. What you have is that, basically, in this case, the tiles are each tiles containing four patches. So basically, it's like having that in each patch, you get a flat signal because edges, it's like between one image and the other. But this is like the ideal case. And what you get, it's a surprisingly good denoising results and you can measure by the PSNR. I don't have much time. The results are very good. Okay. But now, if you do this in a natural image, you will see these continuities at image boundaries. Because you are taking like one patch and next to the other. And even in this, so this is like an ideal case, now I prepare a pathological case. Now, I shift the checker board like one hole and one hole down and one column left. Now, each patch, you see, it contains these guys. It contains like two edges or at least one edge. Okay. And now, let's draw the 1D illustration. In the 1D illustration, in one case, you have a flat signal and this is extremely good to be denoised by, even by the local averages. In the other case, you have like this, where the last guy is here. So, this is like a spike. So, this is equivalent to have a noisy free signal that is like this, spike. That's a nightmare. So, if you look at the coefficients, these are extremely sparse. You have only the first one, which is no zero. And the others, which I just know is, here, if you go in the DCT domain, you have all the coefficients which are no zero. Those sparsity doesn't work. So, if your first sparsity on this type of signal, it doesn't work as an assumption. I mean, by the DCT basis, you can represent any patch. Our assumption is that our natural patches can be sparsely represented. And for this pathological case, it doesn't work. Okay. And now, the issue, you can see, if you perform denoising, what you get are a lot of ringing artifacts. Can you see that? Here, really? Nice. Okay. So, how to solve this problem? Well, the idea on how to solve this problem is that rather than computing the noise, which also solves the problem in natural images, that you might have discontinuities in patches. Rather than doing this operation, the denoising, okay, rather than doing this pipeline, all the patches extracted from a tile, you do, you repeat these for each and every piece. Okay. And this gives you this lighting DCT algorithm, which is what you need to implement today in the assignment. This lighting DCT, which means for each pixel, now, EX is, let's say for each pixel X equal to RC, then I use DZs for the representation. Okay. You extract the patch S, okay, and then you perform the analysis, the thresholding, and the synthesis. Okay. So this means that, for given your image, you obtain an estimate for this patch, which corresponds to this pixel, the central pixel of the patch. Then you take the neighboring patch, which is this one, and you obtain another estimate. Then you take another patch and you obtain another estimate. Okay. So you're doing this for each and every pixel in the image. So if you are at the center of the image, for each pixel, you will get 64 estimates. Right. This solves the problem I was showing there because in any case, for any image is regarding the shifts, you will have the same estimates. Okay. So this makes the algorithm translation invariant, but then you need to decide what to do with all these estimates and the idea is to average them. So basically, your final image, your final estimate in your image will be obtained by accumulating all the estimates. Okay. So model of the pattern notation, that would be the pixel R coordinate C, here you take R minus, I don't know, the patch is 8 by 8, so R minus 4, R plus 3. And C minus 4, C plus 3, you accumulate your estimate from the patch. Okay. You sum all the estimates together. So for each pixel in your image, so if you do a 3D visualization, you have multiple estimates for all the patches that are overlapping this pixel. And these are stuck there. Then you average them together. Okay. So depending on the way you average them, you get different performance and then conclude. So if you just compute the average, like the plain average, this is very simple to do. You just need to take a matrix, a weight matrix, where you sum up one, such that you... Okay. If you are at the center of the pixel, you divide by 64. At the end, if you are at the periphery, this pixel will receive less estimates. So you need to divide by the number of pixels you have been summing up. But this is not very compliant with our prior, because we know that not all the pixels, not all the patches, will provide estimates that are good the same. Like if I go to the checkerboard example, the checkerboard example is here. If I go to the checkerboard example, this patch, which is entirely included, will be very good. Or say, this patch, which is entirely included, is very good for obtaining this estimate. This patch, which is not entirely included, will be not very good. So in order to leverage my prior, even in this aggregation phase, you will use some weights that promote estimates coming from patches that are compliant with your prior, like patches that have a sparse representation. So rather than summing up together, just averaging all the estimates, you will give some weights, which is typically given by this guy, which is the number of new zero coefficients of your patch. So by doing so, the more sparse the patch, the more influential that patch will be when aggregating on the estimates. Okay. And I can show you what happens, but then this is something you can implement really in a couple of for loops. I don't know why it's taking so much. Otherwise, okay, I think I will upload this on my slides, on my site, just let's check whether it works. Because then you see that if you do sliding the CT, obtaining an estimate for each patch, and then for each patch, you average together all the estimates using weights that are like one over the sparsity of the patch, such that you have larger weights to sparser patches, then you get like estimates that are as good as if you were taking a title. Are we going to see some artifacts along the corners of the image since we have less patches? At the border of the patches, you will have like less effective denoising because you are averaging over only say fewer estimates, that is true. But if you are using these weights at the end of the day, basically you will see that all the patches are like the coefficients, which are when there is an edge, most probably many coefficients won't be sparse. So these will count very little in the average, while the most sparse will take the most. So basically you will give most of the estimates. I'm sorry, but today this doesn't work. I will call the assistants for fixing this. And you please go to the column and try to address this notebook where there is this sliding in the CT with this double loop. And if you have any trouble, ask it or I'll go next.